{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.regularizers import l2\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from keras.applications.imagenet_utils import _obtain_input_shape\n",
    "import keras.backend as K\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.callbacks import *\n",
    "# from keras_contrib.applications import densenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import scipy\n",
    "from PIL import Image\n",
    "from skimage.transform import resize\n",
    "from imageio import imread"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fcn_vgg_8(input_shape, num_classes, weight_decay=5e-4):\n",
    "    img_input = Input(shape=input_shape)\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1')(img_input)\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n",
    "\n",
    "    # Block 2\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv1')(x)\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv2')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n",
    "\n",
    "    # Block 3\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv1')(x)\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv2')(x)\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv3')(x)\n",
    "    vgg_conv3_out = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)\n",
    "\n",
    "    # Block 4\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv1')(vgg_conv3_out)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv2')(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv3')(x)\n",
    "    vgg_conv4_out = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)\n",
    "\n",
    "    # Block 5\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv1')(vgg_conv4_out)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv2')(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv3')(x)\n",
    "    vgg_conv5_out = MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool')(x)\n",
    "    \n",
    "    # convert dense layers to fully conv layers\n",
    "    x = Conv2D(4096, (7, 7), activation='relu', padding='same', name='fc1', kernel_regularizer=l2(weight_decay))(vgg_conv5_out)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Conv2D(4096, (1, 1), activation='relu', padding='same', name='fc2', kernel_regularizer=l2(weight_decay))(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    conv7_out = Conv2D(num_classes, (1, 1), activation='linear', padding='valid', strides=(1, 1), kernel_regularizer=l2(weight_decay), name='decoder_conv7')(x)   \n",
    "\n",
    "    # decoder network\n",
    "    vgg_conv4_conv1x1 = Conv2D(num_classes, (1, 1), activation='relu', padding='valid', strides=(1, 1), kernel_regularizer=l2(weight_decay),\n",
    "                              name=\"layer4_conv1x1\")(vgg_conv4_out)\n",
    "    \n",
    "    vgg_conv3_conv1x1 = Conv2D(num_classes, (1, 1), activation='relu', padding='valid', strides=(1, 1), kernel_regularizer=l2(weight_decay),\n",
    "                              name=\"layer3_conv1x1\")(vgg_conv3_out)\n",
    "    \n",
    "    upsample1 = Conv2DTranspose(num_classes, kernel_size=4, strides=(2,2), padding='same', kernel_regularizer=l2(weight_decay), name='upsample_1')(conv7_out)\n",
    "    \n",
    "    skip1 = Add()([upsample1, vgg_conv4_conv1x1])\n",
    "    upsample2 = Conv2DTranspose(num_classes, kernel_size=4, strides=(2,2), padding='same', kernel_regularizer=l2(weight_decay), name='upsample_2')(skip1)\n",
    "    \n",
    "    skip2 = Add()([upsample2, vgg_conv3_conv1x1])\n",
    "    upsample3 = Conv2DTranspose(num_classes, kernel_size=16, strides=(8,8), padding='same', kernel_regularizer=l2(weight_decay), name='upsample_3')(skip2)\n",
    "    \n",
    "    model = Model(img_input, upsample3)\n",
    "    \n",
    "    layers_list = model.layers\n",
    "    index = {}\n",
    "    \n",
    "    for layer in layers_list:\n",
    "        if layer.name:\n",
    "            index[layer.name] = layer\n",
    "            \n",
    "    vgg16 = VGG16()\n",
    "    for layer in vgg16.layers:\n",
    "        weights = layer.get_weights()\n",
    "        if layer.name=='fc1':\n",
    "            weights[0] = np.reshape(weights[0], (7,7,512,4096))\n",
    "        elif layer.name=='fc2':\n",
    "            weights[0] = np.reshape(weights[0], (1,1,4096,4096))\n",
    "        if layer.name in index:\n",
    "            index[layer.name].set_weights(weights)\n",
    "            index[layer.name].trainable = False\n",
    "            \n",
    "#     weights_path = os.path.expanduser(os.path.join('~', '.keras/models/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5'))\n",
    "#     model.load_weights(weights_path, by_name=True)\n",
    "    return model\n",
    "\n",
    "#     fcn_weights_path = os.path.expanduser(os.path.join('~', '.keras/models/fcn_vgg16_weights_tf_dim_ordering_tf_kernels.h5'))\n",
    "\n",
    "#     #transfer if weights have not been created\n",
    "#     if os.path.isfile(weights_path) == False:\n",
    "#         flattened_layers = model.layers\n",
    "#         index = {}\n",
    "#         for layer in flattened_layers:\n",
    "#             if layer.name:\n",
    "#                 index[layer.name]=layer\n",
    "#         vgg16 = VGG16()\n",
    "#         for layer in vgg16.layers:\n",
    "#             weights = layer.get_weights()\n",
    "#             if layer.name=='fc1':\n",
    "#                 weights[0] = np.reshape(weights[0], (7,7,512,4096))\n",
    "#             elif layer.name=='fc2':\n",
    "#                 weights[0] = np.reshape(weights[0], (1,1,4096,4096))\n",
    "# #             elif layer.name=='predictions':\n",
    "# #                 layer.name='predictions_1000'\n",
    "# #                 weights[0] = np.reshape(weights[0], (1,1,4096,1000))\n",
    "#             if index.has_key(layer.name):\n",
    "#                 index[layer.name].set_weights(weights)\n",
    "#         model.save_weights(weights_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dumping some custom loss/metric functions here to see help me figure out which ones are correct to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/aurora95/Keras-FCN/blob/master/utils/loss_function.py\n",
    "def softmax_sparse_crossentropy_ignoring_last_label(y_true, y_pred):\n",
    "    y_pred = K.reshape(y_pred, (-1, K.int_shape(y_pred)[-1]))\n",
    "    log_softmax = tf.nn.log_softmax(y_pred)\n",
    "\n",
    "    y_true = K.one_hot(tf.to_int32(K.flatten(y_true)), K.int_shape(y_pred)[-1]+1)\n",
    "    unpacked = tf.unstack(y_true, axis=-1)\n",
    "    y_true = tf.stack(unpacked[:-1], axis=-1)\n",
    "\n",
    "    cross_entropy = -K.sum(y_true * log_softmax, axis=1)\n",
    "    cross_entropy_mean = K.mean(cross_entropy)\n",
    "\n",
    "    return cross_entropy_mean\n",
    "\n",
    "\n",
    "# Softmax cross-entropy loss function for coco segmentation\n",
    "# and models which expect but do not apply sigmoid on each entry\n",
    "# tensorlow only\n",
    "def binary_crossentropy_with_logits(ground_truth, predictions):\n",
    "    return K.mean(K.binary_crossentropy(ground_truth,\n",
    "                                        predictions,\n",
    "                                        from_logits=True),\n",
    "                  axis=-1)\n",
    "def sparse_accuracy_ignoring_last_label(y_true, y_pred):\n",
    "    nb_classes = K.int_shape(y_pred)[-1]\n",
    "    y_pred = K.reshape(y_pred, (-1, nb_classes))\n",
    "\n",
    "    y_true = K.one_hot(tf.to_int32(K.flatten(y_true)),\n",
    "                       nb_classes + 1)\n",
    "    unpacked = tf.unstack(y_true, axis=-1)\n",
    "    legal_labels = ~tf.cast(unpacked[-1], tf.bool)\n",
    "    y_true = tf.stack(unpacked[:-1], axis=-1)\n",
    "\n",
    "    return K.sum(tf.to_float(legal_labels & K.equal(K.argmax(y_true, axis=-1), K.argmax(y_pred, axis=-1)))) / K.sum(tf.to_float(legal_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fcn_binary_crossentropy(y_true, y_pred, from_logits=False):\n",
    "    pred_shape = K.int_shape(y_pred)\n",
    "    true_shape = K.int_shape(y_true)\n",
    "    y_pred_reshaped = K.reshape(y_pred, (-1, 2))\n",
    "    y_true_reshaped = K.reshape(y_true, (-1, 2))\n",
    "\n",
    "    result = K.binary_crossentropy(y_pred_reshaped, y_true_reshaped,\n",
    "                                   from_logits=from_logits)\n",
    "    result = K.mean(result, axis=-1)\n",
    "\n",
    "    if len(true_shape) >= 3:\n",
    "        return K.reshape(result, true_shape[:-1])\n",
    "    else:\n",
    "        return result\n",
    "    \n",
    "def fcn_binary_crossentropy_with_regularisation(y_true, y_pred, from_logits=False):\n",
    "    loss1 = fcn_binary_crossentropy(y_true, y_pred, from_logits=from_logits)\n",
    "    loss2 = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES) + 5e-4 + K.sum(tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES))\n",
    "    \n",
    "    return K.sum(loss1, loss2)\n",
    "\n",
    "def pixelwise_crossentropy(target, output):\n",
    "    output = tf.clip_by_value(output, 10e-8, 1. - 10e-8)\n",
    "    return - tf.reduce_sum(target * tf.log(output))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://raw.githubusercontent.com/theduynguyen/Keras-FCN/master/loss_func.py\n",
    "\n",
    "def fcn_xent(y_true, y_pred):\n",
    "\ty_true_reshaped = K.flatten(y_true)\n",
    "\ty_pred_reshaped = K.flatten(y_pred)\n",
    "\n",
    "\treturn K.binary_crossentropy(y_pred_reshaped, y_true_reshaped)\n",
    "\n",
    "\n",
    "def pixel_acc(y_true, y_pred):\n",
    "\ts = K.shape(y_true)\n",
    "\n",
    "\t# reshape such that w and h dim are multiplied together\n",
    "\ty_true_reshaped = K.reshape( y_true, tf.stack( [-1, s[1]*s[2], s[-1]] ) )\n",
    "\ty_pred_reshaped = K.reshape( y_pred, tf.stack( [-1, s[1]*s[2], s[-1]] ) )\n",
    "\n",
    "\t# correctly classified\n",
    "\tclf_pred = K.one_hot( K.argmax(y_pred_reshaped),s[-1])\n",
    "\tcorrect_pixels_per_class = K.cast( K.equal(clf_pred,y_true_reshaped), dtype='float32')\n",
    "\n",
    "\treturn K.sum(correct_pixels_per_class) / K.cast(K.prod(s), dtype='float32')\n",
    "\n",
    "def mean_acc(y_true, y_pred):\n",
    "\ts = K.shape(y_true)\n",
    "\n",
    "\t# reshape such that w and h dim are multiplied together\n",
    "\ty_true_reshaped = K.reshape( y_true, tf.stack( [-1, s[1]*s[2], s[-1]] ) )\n",
    "\ty_pred_reshaped = K.reshape( y_pred, tf.stack( [-1, s[1]*s[2], s[-1]] ) )\n",
    "\n",
    "\t# correctly classified\n",
    "\tclf_pred = K.one_hot( K.argmax(y_pred_reshaped), nb_classes = s[-1])\n",
    "\tequal_entries = K.cast(K.equal(clf_pred,y_true_reshaped), dtype='float32') * y_true_reshaped\n",
    "\n",
    "\tcorrect_pixels_per_class = K.sum(equal_entries, axis=1)\n",
    "\tn_pixels_per_class = K.sum(y_true_reshaped,axis=1)\n",
    "\n",
    "\tacc = correct_pixels_per_class / n_pixels_per_class\n",
    "\tacc_mask = tf.is_finite(acc)\n",
    "\tacc_masked = tf.boolean_mask(acc,acc_mask)\n",
    "\n",
    "\treturn K.mean(acc_masked)\n",
    "\n",
    "def mean_IoU(y_true, y_pred):\n",
    "    s = K.shape(y_true)\n",
    "    y_true_reshaped = K.reshape( y_true, tf.stack( [-1, s[1]*s[2], s[-1]] ) )\n",
    "    y_pred_reshaped = K.reshape( y_pred, tf.stack( [-1, s[1]*s[2], s[-1]] ) )\n",
    "    y_pred_argmax = K.argmax(y_pred_reshaped, axis=-1)\n",
    "    clf_pred = K.one_hot(y_pred_argmax, s[-1])\n",
    "    \n",
    "    equal_entries = K.cast(K.equal(clf_pred,y_true_reshaped), dtype='float32') * y_true_reshaped\n",
    "\n",
    "    intersection = K.sum(equal_entries, axis=1)\n",
    "    union_per_class = K.sum(y_true_reshaped,axis=1) + K.sum(clf_pred,axis=1)\n",
    "\n",
    "    iou = intersection / (union_per_class - intersection)\n",
    "    iou_mask = tf.is_finite(iou)\n",
    "    iou_masked = tf.boolean_mask(iou,iou_mask)\n",
    "\n",
    "    return K.mean( iou_masked )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_base = 0.01\n",
    "fcn_optimizer = SGD(lr=lr_base, momentum=0.9)\n",
    "# https://stackoverflow.com/questions/49715192/tensorflow-mean-iou-for-just-foreground-class-for-binary-semantic-segmentation/50266195#50266195\n",
    "\n",
    "def keras_mean_iou(labels, predictions):\n",
    "    \"\"\"\n",
    "    labels,prediction with shape of [batch,height,width,class_number=2]\n",
    "    \"\"\"\n",
    "    mean_iou = K.variable(0.0)\n",
    "    seen_classes = K.variable(0.0)\n",
    "\n",
    "    for c in range(2):\n",
    "        labels_c = K.cast(K.equal(labels, c), K.floatx())\n",
    "        pred_c = K.cast(K.equal(predictions, c), K.floatx())\n",
    "        \n",
    "    \n",
    "        labels_c_sum = K.sum(labels_c)\n",
    "        pred_c_sum = K.sum(pred_c)\n",
    "\n",
    "        intersect = K.sum(labels_c*pred_c)\n",
    "        union = labels_c_sum + pred_c_sum - intersect\n",
    "        iou = intersect / union\n",
    "        condition = K.equal(union, 0)\n",
    "        mean_iou = K.switch(condition,\n",
    "                            mean_iou,\n",
    "                            mean_iou+iou)\n",
    "        seen_classes = K.switch(condition,\n",
    "                                seen_classes,\n",
    "                                seen_classes+1)\n",
    "\n",
    "    mean_iou = K.switch(K.equal(seen_classes, 0),\n",
    "                        mean_iou,\n",
    "                        mean_iou/seen_classes)\n",
    "    return mean_iou"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the training/gt image paths for data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(10)\n",
    "road_imgs_gt = glob.glob(os.path.join('./data', 'data_road/training', 'gt_image_2', '*_road_*.png'))\n",
    "np.random.shuffle(road_imgs_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./data/data_road/training/gt_image_2/uu_road_000083.png',\n",
       " './data/data_road/training/gt_image_2/uu_road_000062.png',\n",
       " './data/data_road/training/gt_image_2/umm_road_000039.png',\n",
       " './data/data_road/training/gt_image_2/um_road_000068.png',\n",
       " './data/data_road/training/gt_image_2/uu_road_000032.png',\n",
       " './data/data_road/training/gt_image_2/um_road_000045.png',\n",
       " './data/data_road/training/gt_image_2/um_road_000028.png',\n",
       " './data/data_road/training/gt_image_2/umm_road_000061.png',\n",
       " './data/data_road/training/gt_image_2/um_road_000090.png',\n",
       " './data/data_road/training/gt_image_2/umm_road_000054.png']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "road_imgs_gt[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_gt_arr = road_imgs_gt[:16]\n",
    "val_img_arr = [x.replace('gt_image_2', 'image_2').replace('_road_', '_').replace('_lane_', '_') for x in val_gt_arr]\n",
    "train_gt_arr = road_imgs_gt[16:]\n",
    "train_img_arr = [x.replace('gt_image_2', 'image_2').replace('_road_', '_').replace('_lane_', '_') for x in train_gt_arr]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_generator(files_list, gt_list, batch_size, image_shape):\n",
    "\n",
    "    background_color = np.array([1, 0, 0])\n",
    "    images = []\n",
    "    gt_images = []\n",
    "\n",
    "    while True:\n",
    "        for i in range(batch_size):\n",
    "            index = np.random.choice(len(files_list), replace=False)\n",
    "            image_file = files_list[index]\n",
    "            gt_file = gt_list[index]\n",
    "            gt_image = resize(imread(gt_file), image_shape)\n",
    "            \n",
    "            image = resize(imread(image_file), image_shape)\n",
    "\n",
    "            gt_bg_mask = np.all(gt_image == background_color, axis=2)\n",
    "            gt_image_bg = np.zeros(shape=(image_shape[0], image_shape[1]))\n",
    "            gt_image_fg = np.ones(shape=(image_shape[0], image_shape[1]))\n",
    "\n",
    "\n",
    "            gt_image_fg[gt_bg_mask] = 0\n",
    "            gt_image_bg[gt_bg_mask] = 1\n",
    "            \n",
    "            gt_onehot = np.stack((gt_image_fg, gt_image_bg), axis=-1)\n",
    "#             gt_onehot = np.moveaxis(gt_onehot, 0, -1)\n",
    "            \n",
    "            images.append(image)\n",
    "            gt_images.append(gt_onehot)\n",
    "\n",
    "#         yield images, gt_onehot\n",
    "        yield np.array(images), np.array(gt_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(img_shape=(160, 576, 3), batch_size=4, epochs = 2,steps_per_epoch=10, lr=0.001):\n",
    "    K.clear_session()\n",
    "    \n",
    "    tensorboardCB = TensorBoard(log_dir=os.path.join('tensorboard_graphs', 'fcn-keras'), write_graph=True)\n",
    "    checkpointCB = ModelCheckpoint('checkpoints/fcn-run3-epoch{epoch:02d}.h5', save_weights_only=False, mode='max', period=2)\n",
    "    callbacks = [tensorboardCB, checkpointCB]\n",
    "    \n",
    "    IMAGE_SHAPE=img_shape\n",
    "#     IMAGE_SHAPE=(160, 576, 3)\n",
    "    batch_size = batch_size\n",
    "    steps_per_epoch = steps_per_epoch #np.round(len(train_img_arr)/ batch_size)\n",
    "    t_generator = train_generator(train_img_arr, train_gt_arr, batch_size, IMAGE_SHAPE)\n",
    "    val_generator = train_generator(val_img_arr, val_gt_arr, batch_size, IMAGE_SHAPE)\n",
    "    model_fcn = fcn_vgg_8(IMAGE_SHAPE, 2, weight_decay=5e-4)\n",
    "    # freeze layers from vgg for now\n",
    "    for idx, layer in enumerate(model_fcn.layers):\n",
    "        if idx < 17:\n",
    "            layer.trainable = False\n",
    "    model_fcn.summary()\n",
    "#     model_fcn.compile(loss=binary_crossentropy_with_logits,\n",
    "#                   optimizer=Adam(),\n",
    "#                   metrics=[pixelwise_crossentropy]\n",
    "#                      )\n",
    "    \n",
    "    model_fcn.compile(loss=binary_crossentropy_with_logits,\n",
    "                  optimizer=Adam(lr = lr),\n",
    "                  metrics=[mean_IoU]\n",
    "                     )\n",
    "    \n",
    "    history = model_fcn.fit_generator(t_generator, epochs = epochs, steps_per_epoch=steps_per_epoch,\n",
    "                       validation_data = val_generator, validation_steps = 1, \n",
    "                            callbacks=callbacks)\n",
    "    \n",
    "    return model_fcn, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 64, 128, 3)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 64, 128, 64)  1792        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 64, 128, 64)  36928       block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_pool (MaxPooling2D)      (None, 32, 64, 64)   0           block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv1 (Conv2D)           (None, 32, 64, 128)  73856       block1_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv2 (Conv2D)           (None, 32, 64, 128)  147584      block2_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 16, 32, 128)  0           block2_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv1 (Conv2D)           (None, 16, 32, 256)  295168      block2_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv2 (Conv2D)           (None, 16, 32, 256)  590080      block3_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv3 (Conv2D)           (None, 16, 32, 256)  590080      block3_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 8, 16, 256)   0           block3_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv1 (Conv2D)           (None, 8, 16, 512)   1180160     block3_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv2 (Conv2D)           (None, 8, 16, 512)   2359808     block4_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv3 (Conv2D)           (None, 8, 16, 512)   2359808     block4_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 4, 8, 512)    0           block4_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv1 (Conv2D)           (None, 4, 8, 512)    2359808     block4_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv2 (Conv2D)           (None, 4, 8, 512)    2359808     block5_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv3 (Conv2D)           (None, 4, 8, 512)    2359808     block5_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_pool (MaxPooling2D)      (None, 2, 4, 512)    0           block5_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fc1 (Conv2D)                    (None, 2, 4, 4096)   102764544   block5_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 2, 4, 4096)   0           fc1[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "fc2 (Conv2D)                    (None, 2, 4, 4096)   16781312    dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 2, 4, 4096)   0           fc2[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "decoder_conv7 (Conv2D)          (None, 2, 4, 2)      8194        dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "upsample_1 (Conv2DTranspose)    (None, 4, 8, 2)      66          decoder_conv7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "layer4_conv1x1 (Conv2D)         (None, 4, 8, 2)      1026        block4_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 4, 8, 2)      0           upsample_1[0][0]                 \n",
      "                                                                 layer4_conv1x1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "upsample_2 (Conv2DTranspose)    (None, 8, 16, 2)     66          add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "layer3_conv1x1 (Conv2D)         (None, 8, 16, 2)     514         block3_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 8, 16, 2)     0           upsample_2[0][0]                 \n",
      "                                                                 layer3_conv1x1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "upsample_3 (Conv2DTranspose)    (None, 64, 128, 2)   1026        add_2[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 134,271,436\n",
      "Trainable params: 10,892\n",
      "Non-trainable params: 134,260,544\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136/136 [==============================] - 441s 3s/step - loss: 0.7849 - mean_IoU: 0.6404 - val_loss: 0.6141 - val_mean_IoU: 0.8000\n",
      "Epoch 2/6\n",
      "136/136 [==============================] - 1009s 7s/step - loss: 0.5946 - mean_IoU: 0.8267 - val_loss: 0.6417 - val_mean_IoU: 0.7956\n",
      "Epoch 3/6\n",
      "136/136 [==============================] - 1546s 11s/step - loss: 0.5706 - mean_IoU: 0.8541 - val_loss: 0.6238 - val_mean_IoU: 0.8145\n",
      "Epoch 4/6\n",
      "136/136 [==============================] - 2051s 15s/step - loss: 0.5605 - mean_IoU: 0.8660 - val_loss: 0.6356 - val_mean_IoU: 0.8106\n",
      "Epoch 5/6\n",
      "136/136 [==============================] - 2568s 19s/step - loss: 0.5556 - mean_IoU: 0.8715 - val_loss: 0.6144 - val_mean_IoU: 0.8277\n",
      "Epoch 6/6\n",
      " 41/136 [========>.....................] - ETA: 33:58 - loss: 0.5533 - mean_IoU: 0.8742"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[1444,64,64,128] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: block1_conv2/convolution = Conv2D[T=DT_FLOAT, data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](block1_conv1/Relu, block1_conv2/kernel/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: metrics/mean_IoU/Mean_1/_739 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_1330_metrics/mean_IoU/Mean_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'block1_conv2/convolution', defined at:\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 127, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/asyncio/base_events.py\", line 421, in run_forever\n    self._run_once()\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/asyncio/base_events.py\", line 1431, in _run_once\n    handle._run()\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 117, in _handle_events\n    handler_func(fileobj, events)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-20-580de49a5da8>\", line 1, in <module>\n    model, history = run((64,128,3), batch_size=2, epochs=6, steps_per_epoch=len(train_img_arr)//2)\n  File \"<ipython-input-13-87f6a0081ff4>\", line 14, in run\n    model_fcn = fcn_vgg_8(IMAGE_SHAPE, 2, weight_decay=5e-4)\n  File \"<ipython-input-3-731c1c4a0f3e>\", line 4, in fcn_vgg_8\n    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2')(x)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/engine/topology.py\", line 619, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/layers/convolutional.py\", line 168, in call\n    dilation_rate=self.dilation_rate)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 3341, in conv2d\n    data_format=tf_data_format)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\", line 782, in convolution\n    return op(input, filter)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\", line 870, in __call__\n    return self.conv_op(inp, filter)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\", line 522, in __call__\n    return self.call(inp, filter)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\", line 206, in __call__\n    name=self.name)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 953, in conv2d\n    data_format=data_format, dilations=dilations, name=name)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3290, in create_op\n    op_def=op_def)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1654, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[1444,64,64,128] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: block1_conv2/convolution = Conv2D[T=DT_FLOAT, data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](block1_conv1/Relu, block1_conv2/kernel/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: metrics/mean_IoU/Mean_1/_739 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_1330_metrics/mean_IoU/Mean_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1311\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1312\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1419\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1420\u001b[0;31m             status, run_metadata)\n\u001b[0m\u001b[1;32m   1421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    517\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[1444,64,64,128] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: block1_conv2/convolution = Conv2D[T=DT_FLOAT, data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](block1_conv1/Relu, block1_conv2/kernel/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: metrics/mean_IoU/Mean_1/_739 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_1330_metrics/mean_IoU/Mean_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-580de49a5da8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_img_arr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-13-87f6a0081ff4>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(img_shape, batch_size, epochs, steps_per_epoch, lr)\u001b[0m\n\u001b[1;32m     30\u001b[0m     history = model_fcn.fit_generator(t_generator, epochs = epochs, steps_per_epoch=steps_per_epoch,\n\u001b[1;32m     31\u001b[0m                        \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m                             callbacks=callbacks)\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel_fcn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2228\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   2229\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2230\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   2231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2232\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1881\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1883\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1884\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1885\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2480\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2481\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2482\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2483\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1140\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1141\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1321\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1338\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1340\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[1444,64,64,128] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: block1_conv2/convolution = Conv2D[T=DT_FLOAT, data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](block1_conv1/Relu, block1_conv2/kernel/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: metrics/mean_IoU/Mean_1/_739 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_1330_metrics/mean_IoU/Mean_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'block1_conv2/convolution', defined at:\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 127, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/asyncio/base_events.py\", line 421, in run_forever\n    self._run_once()\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/asyncio/base_events.py\", line 1431, in _run_once\n    handle._run()\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 117, in _handle_events\n    handler_func(fileobj, events)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-20-580de49a5da8>\", line 1, in <module>\n    model, history = run((64,128,3), batch_size=2, epochs=6, steps_per_epoch=len(train_img_arr)//2)\n  File \"<ipython-input-13-87f6a0081ff4>\", line 14, in run\n    model_fcn = fcn_vgg_8(IMAGE_SHAPE, 2, weight_decay=5e-4)\n  File \"<ipython-input-3-731c1c4a0f3e>\", line 4, in fcn_vgg_8\n    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2')(x)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/engine/topology.py\", line 619, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/layers/convolutional.py\", line 168, in call\n    dilation_rate=self.dilation_rate)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 3341, in conv2d\n    data_format=tf_data_format)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\", line 782, in convolution\n    return op(input, filter)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\", line 870, in __call__\n    return self.conv_op(inp, filter)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\", line 522, in __call__\n    return self.call(inp, filter)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\", line 206, in __call__\n    name=self.name)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 953, in conv2d\n    data_format=data_format, dilations=dilations, name=name)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3290, in create_op\n    op_def=op_def)\n  File \"/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1654, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[1444,64,64,128] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: block1_conv2/convolution = Conv2D[T=DT_FLOAT, data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](block1_conv1/Relu, block1_conv2/kernel/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: metrics/mean_IoU/Mean_1/_739 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_1330_metrics/mean_IoU/Mean_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n"
     ]
    }
   ],
   "source": [
    "model, history = run((64,128,3), batch_size=2, epochs=6, steps_per_epoch=len(train_img_arr)//2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_with_gpu_clear(img_shape=(160, 576, 3), batch_size=4, epochs = 2,steps_per_epoch=10, lr=0.001):\n",
    "    K.clear_session()\n",
    "    \n",
    "    tensorboardCB = TensorBoard(log_dir=os.path.join('tensorboard_graphs', 'fcn-keras'), write_graph=True)\n",
    "    checkpointCB = ModelCheckpoint('checkpoints/fcn-run3-epoch{epoch:02d}.h5', save_weights_only=False, mode='max', period=2)\n",
    "    callbacks = [tensorboardCB, checkpointCB]\n",
    "    t_generator = train_generator(train_img_arr, train_gt_arr, batch_size, img_shape)\n",
    "    val_generator = train_generator(val_img_arr, val_gt_arr, batch_size, img_shape)\n",
    "    \n",
    "    \n",
    "    model_fcn = fcn_vgg_8(IMAGE_SHAPE, 2, weight_decay=5e-4)\n",
    "    # freeze layers from vgg for now\n",
    "    for idx, layer in enumerate(model_fcn.layers):\n",
    "        if idx < 17:\n",
    "            layer.trainable = False\n",
    "    model_fcn.summary()\n",
    "#     model_fcn.compile(loss=binary_crossentropy_with_logits,\n",
    "#                   optimizer=Adam(),\n",
    "#                   metrics=[pixelwise_crossentropy]\n",
    "#                      )\n",
    "    \n",
    "    model_fcn.compile(loss=binary_crossentropy_with_logits,\n",
    "                  optimizer=Adam(lr = lr),\n",
    "                  metrics=[mean_IoU]\n",
    "                     )\n",
    "    \n",
    "    history = model_fcn.fit_generator(t_generator, epochs = epochs, steps_per_epoch=steps_per_epoch,\n",
    "                       validation_data = val_generator, validation_steps = 1, \n",
    "                            callbacks=callbacks)\n",
    "    \n",
    "    return model_fcn, history"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
