{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using a CNN for object detection\n",
    "\n",
    "This notebook contains the simple implementation of fine tuning a mobilenet to distinguish between cars and non cars. The prediction task is in a separate notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Lambda, Conv2D, MaxPooling2D, BatchNormalization, Dense, GlobalAveragePooling2D\n",
    "from keras.layers import  Flatten, Reshape, Concatenate, Activation, Dropout\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, TensorBoard, LambdaCallback\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "from keras.applications.mobilenet import MobileNet\n",
    "from keras.applications.vgg16  import VGG16\n",
    "from keras.applications.inception_v3 import InceptionV3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialise the base mobilenet network with pretrained weights\n",
    "The image size is set at 128 (rather than 64 as per input data) as the minimum image size for using imagenet \n",
    "weights is 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_width, img_height = (128,128)\n",
    "model = MobileNet(include_top=False, weights='imagenet', input_shape = (img_width, img_height, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mobilenet model without the final predictions layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 64, 64, 32)        864       \n",
      "_________________________________________________________________\n",
      "conv1_bn (BatchNormalization (None, 64, 64, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv1_relu (Activation)      (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_1 (DepthwiseConv2D)  (None, 64, 64, 32)        288       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_bn (BatchNormaliza (None, 64, 64, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_relu (Activation)  (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_1 (Conv2D)           (None, 64, 64, 64)        2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_1_bn (BatchNormaliza (None, 64, 64, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv_pw_1_relu (Activation)  (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_2 (DepthwiseConv2D)  (None, 32, 32, 64)        576       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_bn (BatchNormaliza (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_relu (Activation)  (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_2 (Conv2D)           (None, 32, 32, 128)       8192      \n",
      "_________________________________________________________________\n",
      "conv_pw_2_bn (BatchNormaliza (None, 32, 32, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_pw_2_relu (Activation)  (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_3 (DepthwiseConv2D)  (None, 32, 32, 128)       1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_3_bn (BatchNormaliza (None, 32, 32, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_dw_3_relu (Activation)  (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_3 (Conv2D)           (None, 32, 32, 128)       16384     \n",
      "_________________________________________________________________\n",
      "conv_pw_3_bn (BatchNormaliza (None, 32, 32, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_pw_3_relu (Activation)  (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_4 (DepthwiseConv2D)  (None, 16, 16, 128)       1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_4_bn (BatchNormaliza (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_dw_4_relu (Activation)  (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_4 (Conv2D)           (None, 16, 16, 256)       32768     \n",
      "_________________________________________________________________\n",
      "conv_pw_4_bn (BatchNormaliza (None, 16, 16, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_4_relu (Activation)  (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_5 (DepthwiseConv2D)  (None, 16, 16, 256)       2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_bn (BatchNormaliza (None, 16, 16, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_relu (Activation)  (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_5 (Conv2D)           (None, 16, 16, 256)       65536     \n",
      "_________________________________________________________________\n",
      "conv_pw_5_bn (BatchNormaliza (None, 16, 16, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_5_relu (Activation)  (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_6 (DepthwiseConv2D)  (None, 8, 8, 256)         2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_bn (BatchNormaliza (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_relu (Activation)  (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_6 (Conv2D)           (None, 8, 8, 512)         131072    \n",
      "_________________________________________________________________\n",
      "conv_pw_6_bn (BatchNormaliza (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_6_relu (Activation)  (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_7 (DepthwiseConv2D)  (None, 8, 8, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_bn (BatchNormaliza (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_relu (Activation)  (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_7 (Conv2D)           (None, 8, 8, 512)         262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_7_bn (BatchNormaliza (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_7_relu (Activation)  (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_8 (DepthwiseConv2D)  (None, 8, 8, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_bn (BatchNormaliza (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_relu (Activation)  (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_8 (Conv2D)           (None, 8, 8, 512)         262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_8_bn (BatchNormaliza (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_8_relu (Activation)  (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_9 (DepthwiseConv2D)  (None, 8, 8, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_bn (BatchNormaliza (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_relu (Activation)  (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_9 (Conv2D)           (None, 8, 8, 512)         262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_9_bn (BatchNormaliza (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_9_relu (Activation)  (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_10 (DepthwiseConv2D) (None, 8, 8, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_bn (BatchNormaliz (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_relu (Activation) (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_10 (Conv2D)          (None, 8, 8, 512)         262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_10_bn (BatchNormaliz (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_10_relu (Activation) (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_11 (DepthwiseConv2D) (None, 8, 8, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_bn (BatchNormaliz (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_relu (Activation) (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_11 (Conv2D)          (None, 8, 8, 512)         262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_11_bn (BatchNormaliz (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_11_relu (Activation) (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_12 (DepthwiseConv2D) (None, 4, 4, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_bn (BatchNormaliz (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_relu (Activation) (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_12 (Conv2D)          (None, 4, 4, 1024)        524288    \n",
      "_________________________________________________________________\n",
      "conv_pw_12_bn (BatchNormaliz (None, 4, 4, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_12_relu (Activation) (None, 4, 4, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_13 (DepthwiseConv2D) (None, 4, 4, 1024)        9216      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_bn (BatchNormaliz (None, 4, 4, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_relu (Activation) (None, 4, 4, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_13 (Conv2D)          (None, 4, 4, 1024)        1048576   \n",
      "_________________________________________________________________\n",
      "conv_pw_13_bn (BatchNormaliz (None, 4, 4, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_13_relu (Activation) (None, 4, 4, 1024)        0         \n",
      "=================================================================\n",
      "Total params: 3,228,864\n",
      "Trainable params: 3,206,976\n",
      "Non-trainable params: 21,888\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for layer in model.layers:\n",
    "    layer.trainable = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_model(pretrained_model):\n",
    "    x = GlobalAveragePooling2D()(pretrained_model.output)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    \n",
    "    x = Dense(512, activation=\"relu\")(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    predictions = Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    model_out = Model(inputs = pretrained_model.input, outputs = predictions)\n",
    "    return model_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_custom = build_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 64, 64, 32)        864       \n",
      "_________________________________________________________________\n",
      "conv1_bn (BatchNormalization (None, 64, 64, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv1_relu (Activation)      (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_1 (DepthwiseConv2D)  (None, 64, 64, 32)        288       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_bn (BatchNormaliza (None, 64, 64, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_relu (Activation)  (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_1 (Conv2D)           (None, 64, 64, 64)        2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_1_bn (BatchNormaliza (None, 64, 64, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv_pw_1_relu (Activation)  (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_2 (DepthwiseConv2D)  (None, 32, 32, 64)        576       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_bn (BatchNormaliza (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_relu (Activation)  (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_2 (Conv2D)           (None, 32, 32, 128)       8192      \n",
      "_________________________________________________________________\n",
      "conv_pw_2_bn (BatchNormaliza (None, 32, 32, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_pw_2_relu (Activation)  (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_3 (DepthwiseConv2D)  (None, 32, 32, 128)       1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_3_bn (BatchNormaliza (None, 32, 32, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_dw_3_relu (Activation)  (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_3 (Conv2D)           (None, 32, 32, 128)       16384     \n",
      "_________________________________________________________________\n",
      "conv_pw_3_bn (BatchNormaliza (None, 32, 32, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_pw_3_relu (Activation)  (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_4 (DepthwiseConv2D)  (None, 16, 16, 128)       1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_4_bn (BatchNormaliza (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_dw_4_relu (Activation)  (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_4 (Conv2D)           (None, 16, 16, 256)       32768     \n",
      "_________________________________________________________________\n",
      "conv_pw_4_bn (BatchNormaliza (None, 16, 16, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_4_relu (Activation)  (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_5 (DepthwiseConv2D)  (None, 16, 16, 256)       2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_bn (BatchNormaliza (None, 16, 16, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_relu (Activation)  (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_5 (Conv2D)           (None, 16, 16, 256)       65536     \n",
      "_________________________________________________________________\n",
      "conv_pw_5_bn (BatchNormaliza (None, 16, 16, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_5_relu (Activation)  (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_6 (DepthwiseConv2D)  (None, 8, 8, 256)         2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_bn (BatchNormaliza (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_relu (Activation)  (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_6 (Conv2D)           (None, 8, 8, 512)         131072    \n",
      "_________________________________________________________________\n",
      "conv_pw_6_bn (BatchNormaliza (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_6_relu (Activation)  (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_7 (DepthwiseConv2D)  (None, 8, 8, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_bn (BatchNormaliza (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_relu (Activation)  (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_7 (Conv2D)           (None, 8, 8, 512)         262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_7_bn (BatchNormaliza (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_7_relu (Activation)  (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_8 (DepthwiseConv2D)  (None, 8, 8, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_bn (BatchNormaliza (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_relu (Activation)  (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_8 (Conv2D)           (None, 8, 8, 512)         262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_8_bn (BatchNormaliza (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_8_relu (Activation)  (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_9 (DepthwiseConv2D)  (None, 8, 8, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_bn (BatchNormaliza (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_relu (Activation)  (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_9 (Conv2D)           (None, 8, 8, 512)         262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_9_bn (BatchNormaliza (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_9_relu (Activation)  (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_10 (DepthwiseConv2D) (None, 8, 8, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_bn (BatchNormaliz (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_relu (Activation) (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_10 (Conv2D)          (None, 8, 8, 512)         262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_10_bn (BatchNormaliz (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_10_relu (Activation) (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_11 (DepthwiseConv2D) (None, 8, 8, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_bn (BatchNormaliz (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_relu (Activation) (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_11 (Conv2D)          (None, 8, 8, 512)         262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_11_bn (BatchNormaliz (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_11_relu (Activation) (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_12 (DepthwiseConv2D) (None, 4, 4, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_bn (BatchNormaliz (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_relu (Activation) (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_12 (Conv2D)          (None, 4, 4, 1024)        524288    \n",
      "_________________________________________________________________\n",
      "conv_pw_12_bn (BatchNormaliz (None, 4, 4, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_12_relu (Activation) (None, 4, 4, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_13 (DepthwiseConv2D) (None, 4, 4, 1024)        9216      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_bn (BatchNormaliz (None, 4, 4, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_relu (Activation) (None, 4, 4, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_13 (Conv2D)          (None, 4, 4, 1024)        1048576   \n",
      "_________________________________________________________________\n",
      "conv_pw_13_bn (BatchNormaliz (None, 4, 4, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_13_relu (Activation) (None, 4, 4, 1024)        0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_2 ( (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 4,803,777\n",
      "Trainable params: 1,574,913\n",
      "Non-trainable params: 3,228,864\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_custom.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_custom.compile(loss='binary_crossentropy',\n",
    "              optimizer=Adam(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12874 images belonging to 2 classes.\n",
      "Found 3444 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_data_dir ='data_keras/train'\n",
    "val_data_dir = 'data_keras/test'\n",
    "batch_size = 32\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    "    horizontal_flip = True,\n",
    "    fill_mode = \"nearest\",\n",
    "    zoom_range = 0.3,\n",
    "    width_shift_range = 0.3,\n",
    "    height_shift_range=0.3,\n",
    "    rotation_range=30)\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(128,128),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "validation_generator = val_datagen.flow_from_directory(\n",
    "    val_data_dir,\n",
    "    target_size=(128,128),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logger(epoch, logs):\n",
    "    if epoch %2== 0:\n",
    "        print(epoch, logs)\n",
    "logging_callback = LambdaCallback(on_epoch_end=logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "401/402 [============================>.] - ETA: 0s - loss: 0.0298 - acc: 0.98990 {'val_loss': 0.028021691536740154, 'val_acc': 0.99036214953271029, 'loss': 0.029776629348816499, 'acc': 0.98987696620464105}\n",
      "402/402 [==============================] - 47s 118ms/step - loss: 0.0297 - acc: 0.9899 - val_loss: 0.0280 - val_acc: 0.9904\n",
      "Epoch 2/50\n",
      "402/402 [==============================] - 46s 115ms/step - loss: 0.0286 - acc: 0.9906 - val_loss: 0.0179 - val_acc: 0.9927\n",
      "Epoch 3/50\n",
      "401/402 [============================>.] - ETA: 0s - loss: 0.0248 - acc: 0.99112 {'val_loss': 0.026628745518741129, 'val_acc': 0.99007009345794394, 'loss': 0.024110861899956041, 'acc': 0.99143435602859442}\n",
      "402/402 [==============================] - 46s 114ms/step - loss: 0.0248 - acc: 0.9911 - val_loss: 0.0266 - val_acc: 0.9901\n",
      "Epoch 4/50\n",
      "402/402 [==============================] - 46s 114ms/step - loss: 0.0312 - acc: 0.9895 - val_loss: 0.0119 - val_acc: 0.9945\n",
      "Epoch 5/50\n",
      "401/402 [============================>.] - ETA: 0s - loss: 0.0242 - acc: 0.99234 {'val_loss': 0.039243812531762685, 'val_acc': 0.98714953271028039, 'loss': 0.024936643703920038, 'acc': 0.99213518143591339}\n",
      "402/402 [==============================] - 46s 113ms/step - loss: 0.0249 - acc: 0.9921 - val_loss: 0.0392 - val_acc: 0.9871\n",
      "Epoch 6/50\n",
      "402/402 [==============================] - 45s 113ms/step - loss: 0.0247 - acc: 0.9914 - val_loss: 0.0203 - val_acc: 0.9933\n",
      "Epoch 7/50\n",
      "401/402 [============================>.] - ETA: 0s - loss: 0.0257 - acc: 0.99176 {'val_loss': 0.011354856196601622, 'val_acc': 0.99561915887850472, 'loss': 0.02594807769568053, 'acc': 0.99168221393034828}\n",
      "402/402 [==============================] - 46s 113ms/step - loss: 0.0259 - acc: 0.9917 - val_loss: 0.0114 - val_acc: 0.9956\n",
      "Epoch 8/50\n",
      "402/402 [==============================] - 45s 113ms/step - loss: 0.0254 - acc: 0.9921 - val_loss: 0.0127 - val_acc: 0.9956\n",
      "Epoch 9/50\n",
      "401/402 [============================>.] - ETA: 0s - loss: 0.0250 - acc: 0.99278 {'val_loss': 0.015045205690588875, 'val_acc': 0.99415887850467288, 'loss': 0.025029271615889977, 'acc': 0.99268026787104813}\n",
      "402/402 [==============================] - 46s 113ms/step - loss: 0.0250 - acc: 0.9927 - val_loss: 0.0150 - val_acc: 0.9942\n",
      "Epoch 10/50\n",
      "402/402 [==============================] - 45s 112ms/step - loss: 0.0172 - acc: 0.9937 - val_loss: 0.0209 - val_acc: 0.9936\n",
      "Epoch 11/50\n",
      "401/402 [============================>.] - ETA: 0s - loss: 0.0262 - acc: 0.990110 {'val_loss': 0.015848644137583513, 'val_acc': 0.9929906542056075, 'loss': 0.026218586500871093, 'acc': 0.9901105746768416}\n",
      "402/402 [==============================] - 45s 113ms/step - loss: 0.0262 - acc: 0.9901 - val_loss: 0.0158 - val_acc: 0.9930\n",
      "Epoch 12/50\n",
      "402/402 [==============================] - 45s 112ms/step - loss: 0.0218 - acc: 0.9928 - val_loss: 0.0140 - val_acc: 0.9950\n",
      "Epoch 13/50\n",
      "401/402 [============================>.] - ETA: 0s - loss: 0.0246 - acc: 0.991312 {'val_loss': 0.0090436304986919788, 'val_acc': 0.99620327102803741, 'loss': 0.02407964575668271, 'acc': 0.99151222549147966}\n",
      "402/402 [==============================] - 46s 113ms/step - loss: 0.0246 - acc: 0.9914 - val_loss: 0.0090 - val_acc: 0.9962\n",
      "Epoch 14/50\n",
      "402/402 [==============================] - 45s 112ms/step - loss: 0.0240 - acc: 0.9924 - val_loss: 0.0247 - val_acc: 0.9921\n",
      "Epoch 15/50\n",
      "401/402 [============================>.] - ETA: 0s - loss: 0.0220 - acc: 0.992314 {'val_loss': 0.016239582620683705, 'val_acc': 0.99415887850467288, 'loss': 0.021946055680711538, 'acc': 0.99229092041738043}\n",
      "402/402 [==============================] - 45s 112ms/step - loss: 0.0219 - acc: 0.9923 - val_loss: 0.0162 - val_acc: 0.9942\n",
      "Epoch 16/50\n",
      "402/402 [==============================] - 45s 112ms/step - loss: 0.0211 - acc: 0.9920 - val_loss: 0.0092 - val_acc: 0.9965\n",
      "Epoch 17/50\n",
      "401/402 [============================>.] - ETA: 0s - loss: 0.0228 - acc: 0.991516 {'val_loss': 0.0098412407463673232, 'val_acc': 0.99620327102803741, 'loss': 0.022750982768708346, 'acc': 0.99151222551004514}\n",
      "402/402 [==============================] - 45s 112ms/step - loss: 0.0227 - acc: 0.9915 - val_loss: 0.0098 - val_acc: 0.9962\n",
      "Epoch 18/50\n",
      "402/402 [==============================] - 45s 112ms/step - loss: 0.0228 - acc: 0.9933 - val_loss: 0.0206 - val_acc: 0.9933\n",
      "Epoch 19/50\n",
      "401/402 [============================>.] - ETA: 0s - loss: 0.0219 - acc: 0.993118 {'val_loss': 0.011468088687014022, 'val_acc': 0.99415887850467288, 'loss': 0.022011768614330719, 'acc': 0.99306961532471583}\n",
      "402/402 [==============================] - 45s 112ms/step - loss: 0.0220 - acc: 0.9931 - val_loss: 0.0115 - val_acc: 0.9942\n",
      "Epoch 20/50\n",
      "402/402 [==============================] - 45s 112ms/step - loss: 0.0194 - acc: 0.9946 - val_loss: 0.0092 - val_acc: 0.9968\n",
      "Epoch 21/50\n",
      "401/402 [============================>.] - ETA: 0s - loss: 0.0229 - acc: 0.993620 {'val_loss': 0.014198419884021894, 'val_acc': 0.99415887850467288, 'loss': 0.022897584909832555, 'acc': 0.99361470175985045}\n",
      "402/402 [==============================] - 45s 111ms/step - loss: 0.0229 - acc: 0.9936 - val_loss: 0.0142 - val_acc: 0.9942\n",
      "Epoch 22/50\n",
      "402/402 [==============================] - 45s 112ms/step - loss: 0.0242 - acc: 0.9918 - val_loss: 0.0088 - val_acc: 0.9962\n",
      "Epoch 23/50\n",
      "401/402 [============================>.] - ETA: 0s - loss: 0.0223 - acc: 0.993122 {'val_loss': 0.022706332669320855, 'val_acc': 0.99328271028037385, 'loss': 0.022240846228608772, 'acc': 0.99306961532471583}\n",
      "402/402 [==============================] - 45s 112ms/step - loss: 0.0222 - acc: 0.9931 - val_loss: 0.0227 - val_acc: 0.9933\n",
      "Epoch 24/50\n",
      "402/402 [==============================] - 45s 112ms/step - loss: 0.0200 - acc: 0.9928 - val_loss: 0.0196 - val_acc: 0.9942\n",
      "Epoch 25/50\n",
      "401/402 [============================>.] - ETA: 0s - loss: 0.0228 - acc: 0.993124 {'val_loss': 0.010351539806319652, 'val_acc': 0.9967873831775701, 'loss': 0.022744757784913264, 'acc': 0.99314748481544934}\n",
      "402/402 [==============================] - 45s 112ms/step - loss: 0.0227 - acc: 0.9932 - val_loss: 0.0104 - val_acc: 0.9968\n",
      "Epoch 26/50\n",
      "402/402 [==============================] - 45s 111ms/step - loss: 0.0200 - acc: 0.9930 - val_loss: 0.0207 - val_acc: 0.9907\n",
      "Epoch 27/50\n",
      "401/402 [============================>.] - ETA: 0s - loss: 0.0193 - acc: 0.994226 {'val_loss': 0.019573724034189773, 'val_acc': 0.99415887850467288, 'loss': 0.019455982481441696, 'acc': 0.99415978819498518}\n",
      "402/402 [==============================] - 45s 111ms/step - loss: 0.0194 - acc: 0.9942 - val_loss: 0.0196 - val_acc: 0.9942\n",
      "Epoch 28/50\n",
      "402/402 [==============================] - 45s 111ms/step - loss: 0.0184 - acc: 0.9947 - val_loss: 0.0143 - val_acc: 0.9962\n",
      "Epoch 29/50\n",
      "401/402 [============================>.] - ETA: 0s - loss: 0.0200 - acc: 0.993128 {'val_loss': 0.010035360993064148, 'val_acc': 0.99737149532710279, 'loss': 0.019978058299251318, 'acc': 0.99306961532471583}\n",
      "402/402 [==============================] - 45s 112ms/step - loss: 0.0200 - acc: 0.9931 - val_loss: 0.0100 - val_acc: 0.9974\n",
      "Epoch 30/50\n",
      "402/402 [==============================] - 45s 111ms/step - loss: 0.0220 - acc: 0.9934 - val_loss: 0.0126 - val_acc: 0.9953\n",
      "Epoch 31/50\n",
      "401/402 [============================>.] - ETA: 0s - loss: 0.0187 - acc: 0.994730 {'val_loss': 0.019460126953520389, 'val_acc': 0.99328271028037385, 'loss': 0.018620558424988883, 'acc': 0.99470487463011992}\n",
      "402/402 [==============================] - 45s 112ms/step - loss: 0.0186 - acc: 0.9947 - val_loss: 0.0195 - val_acc: 0.9933\n",
      "Epoch 32/50\n",
      "402/402 [==============================] - 45s 112ms/step - loss: 0.0174 - acc: 0.9938 - val_loss: 0.0061 - val_acc: 0.9982\n",
      "Epoch 33/50\n",
      "401/402 [============================>.] - ETA: 0s - loss: 0.0188 - acc: 0.993632 {'val_loss': 0.0085903463660547165, 'val_acc': 0.99591121495327106, 'loss': 0.018784701049069565, 'acc': 0.99361470175985045}\n",
      "402/402 [==============================] - 45s 111ms/step - loss: 0.0188 - acc: 0.9936 - val_loss: 0.0086 - val_acc: 0.9959\n",
      "Epoch 34/50\n",
      "402/402 [==============================] - 45s 111ms/step - loss: 0.0211 - acc: 0.9935 - val_loss: 0.0092 - val_acc: 0.9965\n",
      "Epoch 35/50\n",
      "401/402 [============================>.] - ETA: 0s - loss: 0.0209 - acc: 0.992534 {'val_loss': 0.017405398575919797, 'val_acc': 0.99532710280373837, 'loss': 0.020863399374855925, 'acc': 0.9925373134328358}\n",
      "402/402 [==============================] - 45s 112ms/step - loss: 0.0209 - acc: 0.9925 - val_loss: 0.0174 - val_acc: 0.9953\n",
      "Epoch 36/50\n",
      "402/402 [==============================] - 45s 111ms/step - loss: 0.0188 - acc: 0.9946 - val_loss: 0.0185 - val_acc: 0.9953\n",
      "Epoch 37/50\n",
      "401/402 [============================>.] - ETA: 0s - loss: 0.0162 - acc: 0.994236 {'val_loss': 0.0038660166260265491, 'val_acc': 0.99912383177570097, 'loss': 0.016161134156908553, 'acc': 0.9942376576857187}\n",
      "402/402 [==============================] - 45s 112ms/step - loss: 0.0161 - acc: 0.9942 - val_loss: 0.0039 - val_acc: 0.9991\n",
      "Epoch 38/50\n",
      "402/402 [==============================] - 45s 111ms/step - loss: 0.0185 - acc: 0.9946 - val_loss: 0.0145 - val_acc: 0.9945\n",
      "Epoch 39/50\n",
      "401/402 [============================>.] - ETA: 0s - loss: 0.0193 - acc: 0.993838 {'val_loss': 0.021869888426374315, 'val_acc': 0.99328271028037385, 'loss': 0.019350221133983343, 'acc': 0.99384831023205111}\n",
      "402/402 [==============================] - 45s 111ms/step - loss: 0.0193 - acc: 0.9939 - val_loss: 0.0219 - val_acc: 0.9933\n",
      "Epoch 40/50\n",
      "402/402 [==============================] - 45s 111ms/step - loss: 0.0196 - acc: 0.9936 - val_loss: 0.0097 - val_acc: 0.9959\n",
      "Epoch 41/50\n",
      "401/402 [============================>.] - ETA: 0s - loss: 0.0218 - acc: 0.992840 {'val_loss': 0.01455868506101367, 'val_acc': 0.99445093457943923, 'loss': 0.021793391304814998, 'acc': 0.99275813736178165}\n",
      "402/402 [==============================] - 44s 111ms/step - loss: 0.0218 - acc: 0.9928 - val_loss: 0.0146 - val_acc: 0.9945\n",
      "Epoch 42/50\n",
      "402/402 [==============================] - 45s 111ms/step - loss: 0.0199 - acc: 0.9932 - val_loss: 0.0262 - val_acc: 0.9909\n",
      "Epoch 43/50\n",
      "401/402 [============================>.] - ETA: 0s - loss: 0.0152 - acc: 0.994542 {'val_loss': 0.0056675458464122315, 'val_acc': 0.99737149532710279, 'loss': 0.015185554161563235, 'acc': 0.99454913564865288}\n",
      "402/402 [==============================] - 45s 111ms/step - loss: 0.0152 - acc: 0.9946 - val_loss: 0.0057 - val_acc: 0.9974\n",
      "Epoch 44/50\n",
      "402/402 [==============================] - 45s 111ms/step - loss: 0.0208 - acc: 0.9942 - val_loss: 0.0104 - val_acc: 0.9959\n",
      "Epoch 45/50\n",
      "401/402 [============================>.] - ETA: 0s - loss: 0.0163 - acc: 0.994044 {'val_loss': 0.0092135805885042669, 'val_acc': 0.9967873831775701, 'loss': 0.015434449565251548, 'acc': 0.99408191868568618}\n",
      "402/402 [==============================] - 45s 111ms/step - loss: 0.0164 - acc: 0.9939 - val_loss: 0.0092 - val_acc: 0.9968\n",
      "Epoch 46/50\n",
      "402/402 [==============================] - 45s 112ms/step - loss: 0.0190 - acc: 0.9932 - val_loss: 0.0097 - val_acc: 0.9956\n",
      "Epoch 47/50\n",
      "401/402 [============================>.] - ETA: 0s - loss: 0.0192 - acc: 0.993046 {'val_loss': 0.01022095142419747, 'val_acc': 0.99561915887850472, 'loss': 0.019221337263436226, 'acc': 0.9929917458339822}\n",
      "402/402 [==============================] - 45s 112ms/step - loss: 0.0192 - acc: 0.9930 - val_loss: 0.0102 - val_acc: 0.9956\n",
      "Epoch 48/50\n",
      "402/402 [==============================] - 45s 111ms/step - loss: 0.0197 - acc: 0.9936 - val_loss: 0.0085 - val_acc: 0.9962\n",
      "Epoch 49/50\n",
      "401/402 [============================>.] - ETA: 0s - loss: 0.0148 - acc: 0.995648 {'val_loss': 0.0097703541355980989, 'val_acc': 0.99474299065420557, 'loss': 0.014795406891949393, 'acc': 0.99563930851892224}\n",
      "402/402 [==============================] - 45s 111ms/step - loss: 0.0148 - acc: 0.9956 - val_loss: 0.0098 - val_acc: 0.9947\n",
      "Epoch 50/50\n",
      "402/402 [==============================] - 45s 111ms/step - loss: 0.0157 - acc: 0.9946 - val_loss: 0.0096 - val_acc: 0.9956\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1c10a25358>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_train_samples = 12874\n",
    "nb_validation_samples = 3444\n",
    "epochs = 50\n",
    "batch_size = 32\n",
    "\n",
    "model_custom.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=nb_train_samples// batch_size,\n",
    "    epochs=epochs,\n",
    "    shuffle=True,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=nb_validation_samples//batch_size,\n",
    "    callbacks=[logging_callback, ModelCheckpoint('./models/mobilenet_finetune_v2.h5', save_best_only=True),\n",
    "                   TensorBoard(log_dir='./logs/mobilenet_finetune/v2' )]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_custom.save('./models/mobilenet_finetune_v2_50epochs.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
