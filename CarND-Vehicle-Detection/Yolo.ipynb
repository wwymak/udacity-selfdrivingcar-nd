{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=16\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "activation=leaky\n",
    "\n",
    "[maxpool]\n",
    "size=2\n",
    "stride=2\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=32\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "activation=leaky\n",
    "\n",
    "[maxpool]\n",
    "size=2\n",
    "stride=2\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=64\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "activation=leaky\n",
    "\n",
    "[maxpool]\n",
    "size=2\n",
    "stride=2\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=128\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "activation=leaky\n",
    "\n",
    "[maxpool]\n",
    "size=2\n",
    "stride=2\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=256\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "activation=leaky\n",
    "\n",
    "[maxpool]\n",
    "size=2\n",
    "stride=2\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=512\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "activation=leaky\n",
    "\n",
    "[maxpool]\n",
    "size=2\n",
    "stride=1\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "filters=1024\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "activation=leaky\n",
    "\n",
    "###########\n",
    "\n",
    "[convolutional]\n",
    "batch_normalize=1\n",
    "size=3\n",
    "stride=1\n",
    "pad=1\n",
    "filters=512\n",
    "activation=leaky\n",
    "\n",
    "[convolutional]\n",
    "size=1\n",
    "stride=1\n",
    "pad=1\n",
    "filters=425\n",
    "activation=linear\n",
    "\n",
    "[region]\n",
    "anchors =  0.57273, 0.677385, 1.87446, 2.06253, 3.33843, 5.47434, 7.88282, 3.52778, 9.77052, 9.16828\n",
    "bias_match=1\n",
    "classes=80\n",
    "coords=4\n",
    "num=5\n",
    "softmax=1\n",
    "jitter=.2\n",
    "rescore=0\n",
    "\n",
    "object_scale=5\n",
    "noobject_scale=1\n",
    "class_scale=1\n",
    "coord_scale=1\n",
    "\n",
    "absolute=1\n",
    "thresh = .6\n",
    "random=1\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras.backend as K\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, Conv2D\n",
    "from keras.layers import AveragePooling2D, concatenate, Input, Lambda, Cropping2D, GlobalAveragePooling2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.layers import concatenate, Reshape\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras import utils\n",
    "from keras.callbacks import Callback, LambdaCallback, EarlyStopping, ModelCheckpoint, TensorBoard, LearningRateScheduler, ReduceLROnPlateau\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.regularizers import l2\n",
    "from keras.layers.merge import concatenate\n",
    "import tensorflow as tf\n",
    " \n",
    "from PIL import Image, ImageDraw, ImageFont\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "anchors = [[1.08,1.19],  [3.42,4.41],  [6.63,11.38],  [9.42,5.11],  [16.62,10.52]]\n",
    "classnames = [\n",
    "    \"aeroplane\", \"bicycle\", \"bird\", \"boat\", \"bottle\", \"bus\", \"car\", \"cat\",\n",
    "    \"chair\", \"cow\", \"diningtable\", \"dog\", \"horse\", \"motorbike\", \"person\",\n",
    "    \"pottedplant\", \"sheep\", \"sofa\", \"train\", \"tvmonitor\"\n",
    "]\n",
    "cars_class_number = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "yolo_model = load_model('yolo-vocv2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Layer (type)                    Output Shape         Param #     Connected to                     \n",
    "==================================================================================================\n",
    "input_1 (InputLayer)            (None, 416, 416, 3)  0                                            \n",
    "__________________________________________________________________________________________________\n",
    "conv2d_1 (Conv2D)               (None, 416, 416, 32) 864         input_1[0][0]                    \n",
    "__________________________________________________________________________________________________\n",
    "batch_normalization_1 (BatchNor (None, 416, 416, 32) 128         conv2d_1[0][0]                   \n",
    "__________________________________________________________________________________________________\n",
    "leaky_re_lu_1 (LeakyReLU)       (None, 416, 416, 32) 0           batch_normalization_1[0][0]      \n",
    "__________________________________________________________________________________________________\n",
    "max_pooling2d_1 (MaxPooling2D)  (None, 208, 208, 32) 0           leaky_re_lu_1[0][0]              \n",
    "__________________________________________________________________________________________________\n",
    "conv2d_2 (Conv2D)               (None, 208, 208, 64) 18432       max_pooling2d_1[0][0]            \n",
    "__________________________________________________________________________________________________\n",
    "batch_normalization_2 (BatchNor (None, 208, 208, 64) 256         conv2d_2[0][0]                   \n",
    "__________________________________________________________________________________________________\n",
    "leaky_re_lu_2 (LeakyReLU)       (None, 208, 208, 64) 0           batch_normalization_2[0][0]      \n",
    "__________________________________________________________________________________________________\n",
    "max_pooling2d_2 (MaxPooling2D)  (None, 104, 104, 64) 0           leaky_re_lu_2[0][0]              \n",
    "__________________________________________________________________________________________________\n",
    "conv2d_3 (Conv2D)               (None, 104, 104, 128 73728       max_pooling2d_2[0][0]            \n",
    "__________________________________________________________________________________________________\n",
    "batch_normalization_3 (BatchNor (None, 104, 104, 128 512         conv2d_3[0][0]                   \n",
    "__________________________________________________________________________________________________\n",
    "leaky_re_lu_3 (LeakyReLU)       (None, 104, 104, 128 0           batch_normalization_3[0][0]      \n",
    "__________________________________________________________________________________________________\n",
    "conv2d_4 (Conv2D)               (None, 104, 104, 64) 8192        leaky_re_lu_3[0][0]              \n",
    "__________________________________________________________________________________________________\n",
    "batch_normalization_4 (BatchNor (None, 104, 104, 64) 256         conv2d_4[0][0]                   \n",
    "__________________________________________________________________________________________________\n",
    "leaky_re_lu_4 (LeakyReLU)       (None, 104, 104, 64) 0           batch_normalization_4[0][0]      \n",
    "__________________________________________________________________________________________________\n",
    "conv2d_5 (Conv2D)               (None, 104, 104, 128 73728       leaky_re_lu_4[0][0]              \n",
    "__________________________________________________________________________________________________\n",
    "batch_normalization_5 (BatchNor (None, 104, 104, 128 512         conv2d_5[0][0]                   \n",
    "__________________________________________________________________________________________________\n",
    "leaky_re_lu_5 (LeakyReLU)       (None, 104, 104, 128 0           batch_normalization_5[0][0]      \n",
    "__________________________________________________________________________________________________\n",
    "max_pooling2d_3 (MaxPooling2D)  (None, 52, 52, 128)  0           leaky_re_lu_5[0][0]              \n",
    "__________________________________________________________________________________________________\n",
    "conv2d_6 (Conv2D)               (None, 52, 52, 256)  294912      max_pooling2d_3[0][0]            \n",
    "__________________________________________________________________________________________________\n",
    "batch_normalization_6 (BatchNor (None, 52, 52, 256)  1024        conv2d_6[0][0]                   \n",
    "__________________________________________________________________________________________________\n",
    "leaky_re_lu_6 (LeakyReLU)       (None, 52, 52, 256)  0           batch_normalization_6[0][0]      \n",
    "__________________________________________________________________________________________________\n",
    "conv2d_7 (Conv2D)               (None, 52, 52, 128)  32768       leaky_re_lu_6[0][0]              \n",
    "__________________________________________________________________________________________________\n",
    "batch_normalization_7 (BatchNor (None, 52, 52, 128)  512         conv2d_7[0][0]                   \n",
    "__________________________________________________________________________________________________\n",
    "leaky_re_lu_7 (LeakyReLU)       (None, 52, 52, 128)  0           batch_normalization_7[0][0]      \n",
    "__________________________________________________________________________________________________\n",
    "conv2d_8 (Conv2D)               (None, 52, 52, 256)  294912      leaky_re_lu_7[0][0]              \n",
    "__________________________________________________________________________________________________\n",
    "batch_normalization_8 (BatchNor (None, 52, 52, 256)  1024        conv2d_8[0][0]                   \n",
    "__________________________________________________________________________________________________\n",
    "leaky_re_lu_8 (LeakyReLU)       (None, 52, 52, 256)  0           batch_normalization_8[0][0]      \n",
    "__________________________________________________________________________________________________\n",
    "max_pooling2d_4 (MaxPooling2D)  (None, 26, 26, 256)  0           leaky_re_lu_8[0][0]              \n",
    "__________________________________________________________________________________________________\n",
    "conv2d_9 (Conv2D)               (None, 26, 26, 512)  1179648     max_pooling2d_4[0][0]            \n",
    "__________________________________________________________________________________________________\n",
    "batch_normalization_9 (BatchNor (None, 26, 26, 512)  2048        conv2d_9[0][0]                   \n",
    "__________________________________________________________________________________________________\n",
    "leaky_re_lu_9 (LeakyReLU)       (None, 26, 26, 512)  0           batch_normalization_9[0][0]      \n",
    "__________________________________________________________________________________________________\n",
    "conv2d_10 (Conv2D)              (None, 26, 26, 256)  131072      leaky_re_lu_9[0][0]              \n",
    "__________________________________________________________________________________________________\n",
    "batch_normalization_10 (BatchNo (None, 26, 26, 256)  1024        conv2d_10[0][0]                  \n",
    "__________________________________________________________________________________________________\n",
    "leaky_re_lu_10 (LeakyReLU)      (None, 26, 26, 256)  0           batch_normalization_10[0][0]     \n",
    "__________________________________________________________________________________________________\n",
    "conv2d_11 (Conv2D)              (None, 26, 26, 512)  1179648     leaky_re_lu_10[0][0]             \n",
    "__________________________________________________________________________________________________\n",
    "batch_normalization_11 (BatchNo (None, 26, 26, 512)  2048        conv2d_11[0][0]                  \n",
    "__________________________________________________________________________________________________\n",
    "leaky_re_lu_11 (LeakyReLU)      (None, 26, 26, 512)  0           batch_normalization_11[0][0]     \n",
    "__________________________________________________________________________________________________\n",
    "conv2d_12 (Conv2D)              (None, 26, 26, 256)  131072      leaky_re_lu_11[0][0]             \n",
    "__________________________________________________________________________________________________\n",
    "batch_normalization_12 (BatchNo (None, 26, 26, 256)  1024        conv2d_12[0][0]                  \n",
    "__________________________________________________________________________________________________\n",
    "leaky_re_lu_12 (LeakyReLU)      (None, 26, 26, 256)  0           batch_normalization_12[0][0]     \n",
    "__________________________________________________________________________________________________\n",
    "conv2d_13 (Conv2D)              (None, 26, 26, 512)  1179648     leaky_re_lu_12[0][0]             \n",
    "__________________________________________________________________________________________________\n",
    "batch_normalization_13 (BatchNo (None, 26, 26, 512)  2048        conv2d_13[0][0]                  \n",
    "__________________________________________________________________________________________________\n",
    "leaky_re_lu_13 (LeakyReLU)      (None, 26, 26, 512)  0           batch_normalization_13[0][0]     \n",
    "__________________________________________________________________________________________________\n",
    "max_pooling2d_5 (MaxPooling2D)  (None, 13, 13, 512)  0           leaky_re_lu_13[0][0]             \n",
    "__________________________________________________________________________________________________\n",
    "conv2d_14 (Conv2D)              (None, 13, 13, 1024) 4718592     max_pooling2d_5[0][0]            \n",
    "__________________________________________________________________________________________________\n",
    "batch_normalization_14 (BatchNo (None, 13, 13, 1024) 4096        conv2d_14[0][0]                  \n",
    "__________________________________________________________________________________________________\n",
    "leaky_re_lu_14 (LeakyReLU)      (None, 13, 13, 1024) 0           batch_normalization_14[0][0]     \n",
    "__________________________________________________________________________________________________\n",
    "conv2d_15 (Conv2D)              (None, 13, 13, 512)  524288      leaky_re_lu_14[0][0]             \n",
    "__________________________________________________________________________________________________\n",
    "batch_normalization_15 (BatchNo (None, 13, 13, 512)  2048        conv2d_15[0][0]                  \n",
    "__________________________________________________________________________________________________\n",
    "leaky_re_lu_15 (LeakyReLU)      (None, 13, 13, 512)  0           batch_normalization_15[0][0]     \n",
    "__________________________________________________________________________________________________\n",
    "conv2d_16 (Conv2D)              (None, 13, 13, 1024) 4718592     leaky_re_lu_15[0][0]             \n",
    "__________________________________________________________________________________________________\n",
    "batch_normalization_16 (BatchNo (None, 13, 13, 1024) 4096        conv2d_16[0][0]                  \n",
    "__________________________________________________________________________________________________\n",
    "leaky_re_lu_16 (LeakyReLU)      (None, 13, 13, 1024) 0           batch_normalization_16[0][0]     \n",
    "__________________________________________________________________________________________________\n",
    "conv2d_17 (Conv2D)              (None, 13, 13, 512)  524288      leaky_re_lu_16[0][0]             \n",
    "__________________________________________________________________________________________________\n",
    "batch_normalization_17 (BatchNo (None, 13, 13, 512)  2048        conv2d_17[0][0]                  \n",
    "__________________________________________________________________________________________________\n",
    "leaky_re_lu_17 (LeakyReLU)      (None, 13, 13, 512)  0           batch_normalization_17[0][0]     \n",
    "__________________________________________________________________________________________________\n",
    "conv2d_18 (Conv2D)              (None, 13, 13, 1024) 4718592     leaky_re_lu_17[0][0]             \n",
    "__________________________________________________________________________________________________\n",
    "batch_normalization_18 (BatchNo (None, 13, 13, 1024) 4096        conv2d_18[0][0]                  \n",
    "__________________________________________________________________________________________________\n",
    "leaky_re_lu_18 (LeakyReLU)      (None, 13, 13, 1024) 0           batch_normalization_18[0][0]     \n",
    "__________________________________________________________________________________________________\n",
    "conv2d_19 (Conv2D)              (None, 13, 13, 1024) 9437184     leaky_re_lu_18[0][0]             \n",
    "__________________________________________________________________________________________________\n",
    "batch_normalization_19 (BatchNo (None, 13, 13, 1024) 4096        conv2d_19[0][0]                  \n",
    "__________________________________________________________________________________________________\n",
    "conv2d_21 (Conv2D)              (None, 26, 26, 64)   32768       leaky_re_lu_13[0][0]             \n",
    "__________________________________________________________________________________________________\n",
    "leaky_re_lu_19 (LeakyReLU)      (None, 13, 13, 1024) 0           batch_normalization_19[0][0]     \n",
    "__________________________________________________________________________________________________\n",
    "batch_normalization_21 (BatchNo (None, 26, 26, 64)   256         conv2d_21[0][0]                  \n",
    "__________________________________________________________________________________________________\n",
    "conv2d_20 (Conv2D)              (None, 13, 13, 1024) 9437184     leaky_re_lu_19[0][0]             \n",
    "__________________________________________________________________________________________________\n",
    "leaky_re_lu_21 (LeakyReLU)      (None, 26, 26, 64)   0           batch_normalization_21[0][0]     \n",
    "__________________________________________________________________________________________________\n",
    "batch_normalization_20 (BatchNo (None, 13, 13, 1024) 4096        conv2d_20[0][0]                  \n",
    "__________________________________________________________________________________________________\n",
    "space_to_depth_x2 (Lambda)      (None, 13, 13, 256)  0           leaky_re_lu_21[0][0]             \n",
    "__________________________________________________________________________________________________\n",
    "leaky_re_lu_20 (LeakyReLU)      (None, 13, 13, 1024) 0           batch_normalization_20[0][0]     \n",
    "__________________________________________________________________________________________________\n",
    "concatenate_1 (Concatenate)     (None, 13, 13, 1280) 0           space_to_depth_x2[0][0]          \n",
    "                                                                 leaky_re_lu_20[0][0]             \n",
    "__________________________________________________________________________________________________\n",
    "conv2d_22 (Conv2D)              (None, 13, 13, 1024) 11796480    concatenate_1[0][0]              \n",
    "__________________________________________________________________________________________________\n",
    "batch_normalization_22 (BatchNo (None, 13, 13, 1024) 4096        conv2d_22[0][0]                  \n",
    "__________________________________________________________________________________________________\n",
    "leaky_re_lu_22 (LeakyReLU)      (None, 13, 13, 1024) 0           batch_normalization_22[0][0]     \n",
    "__________________________________________________________________________________________________\n",
    "conv2d_23 (Conv2D)              (None, 13, 13, 125)  128125      leaky_re_lu_22[0][0]             \n",
    "==================================================================================================\n",
    "Total params: 50,676,061\n",
    "Trainable params: 50,655,389\n",
    "Non-trainable params: 20,672\n",
    "__________________________________________________________________________________________________\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IMAGE_H, IMAGE_W = 416, 416\n",
    "GRID_H,  GRID_W  = 13 , 13\n",
    "model_input = Input(shape=(IMAGE_H, IMAGE_W, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def space_to_depth_x2(x):\n",
    "    \"\"\"Thin wrapper for Tensorflow space_to_depth with block_size=2.\"\"\"\n",
    "    # Import currently required to make Lambda work.\n",
    "    # See: https://github.com/fchollet/keras/issues/5088#issuecomment-273851273\n",
    "    import tensorflow as tf\n",
    "    return tf.space_to_depth(x, block_size=2)\n",
    "\n",
    "\n",
    "def space_to_depth_x2_output_shape(input_shape):\n",
    "    \"\"\"Determine space_to_depth output shape for block_size=2.\n",
    "    Note: For Lambda with TensorFlow backend, output shape may not be needed.\n",
    "    \"\"\"\n",
    "    return (input_shape[0], input_shape[1] // 2, input_shape[2] // 2, 4 *\n",
    "            input_shape[3]) if input_shape[1] else (input_shape[0], None, None,\n",
    "                                                    4 * input_shape[3])\n",
    "\n",
    "\n",
    "def yolo_body(inputs, num_anchors, num_classes):\n",
    "    \"\"\"Create YOLO_V2 model CNN body in Keras.\"\"\"\n",
    "    darknet = Model(inputs, darknet_body()(inputs))\n",
    "    conv20 = compose(\n",
    "        DarknetConv2D_BN_Leaky(1024, (3, 3)),\n",
    "        DarknetConv2D_BN_Leaky(1024, (3, 3)))(darknet.output)\n",
    "\n",
    "    conv13 = darknet.layers[43].output\n",
    "    conv21 = DarknetConv2D_BN_Leaky(64, (1, 1))(conv13)\n",
    "    # TODO: Allow Keras Lambda to use func arguments for output_shape?\n",
    "    conv21_reshaped = Lambda(\n",
    "        space_to_depth_x2,\n",
    "        output_shape=space_to_depth_x2_output_shape,\n",
    "        name='space_to_depth')(conv21)\n",
    "\n",
    "    x = concatenate([conv21_reshaped, conv20])\n",
    "    x = DarknetConv2D_BN_Leaky(1024, (3, 3))(x)\n",
    "    x = DarknetConv2D(num_anchors * (num_classes + 5), (1, 1))(x)\n",
    "    return Model(inputs, x)\n",
    "\n",
    "\n",
    "def yolo_head(feats, anchors, num_classes):\n",
    "    \"\"\"Convert final layer features to bounding box parameters.\n",
    "    Parameters\n",
    "    ----------\n",
    "    feats : tensor\n",
    "        Final convolutional layer features.\n",
    "    anchors : array-like\n",
    "        Anchor box widths and heights.\n",
    "    num_classes : int\n",
    "        Number of target classes.\n",
    "    Returns\n",
    "    -------\n",
    "    box_xy : tensor\n",
    "        x, y box predictions adjusted by spatial location in conv layer.\n",
    "    box_wh : tensor\n",
    "        w, h box predictions adjusted by anchors and conv spatial resolution.\n",
    "    box_conf : tensor\n",
    "        Probability estimate for whether each box contains any object.\n",
    "    box_class_pred : tensor\n",
    "        Probability distribution estimate for each box over class labels.\n",
    "    \"\"\"\n",
    "    num_anchors = len(anchors)\n",
    "    # Reshape to batch, height, width, num_anchors, box_params.\n",
    "    anchors_tensor = K.reshape(K.variable(anchors), [1, 1, 1, num_anchors, 2])\n",
    "\n",
    "    # Static implementation for fixed models.\n",
    "    # TODO: Remove or add option for static implementation.\n",
    "    # _, conv_height, conv_width, _ = K.int_shape(feats)\n",
    "    # conv_dims = K.variable([conv_width, conv_height])\n",
    "\n",
    "    # Dynamic implementation of conv dims for fully convolutional model.\n",
    "    conv_dims = K.shape(feats)[1:3]  # assuming channels last\n",
    "    # In YOLO the height index is the inner most iteration.\n",
    "    conv_height_index = K.arange(0, stop=conv_dims[0])\n",
    "    conv_width_index = K.arange(0, stop=conv_dims[1])\n",
    "    conv_height_index = K.tile(conv_height_index, [conv_dims[1]])\n",
    "\n",
    "    # TODO: Repeat_elements and tf.split doesn't support dynamic splits.\n",
    "    # conv_width_index = K.repeat_elements(conv_width_index, conv_dims[1], axis=0)\n",
    "    conv_width_index = K.tile(\n",
    "        K.expand_dims(conv_width_index, 0), [conv_dims[0], 1])\n",
    "    conv_width_index = K.flatten(K.transpose(conv_width_index))\n",
    "    conv_index = K.transpose(K.stack([conv_height_index, conv_width_index]))\n",
    "    conv_index = K.reshape(conv_index, [1, conv_dims[0], conv_dims[1], 1, 2])\n",
    "    conv_index = K.cast(conv_index, K.dtype(feats))\n",
    "\n",
    "    feats = K.reshape(\n",
    "        feats, [-1, conv_dims[0], conv_dims[1], num_anchors, num_classes + 5])\n",
    "    conv_dims = K.cast(K.reshape(conv_dims, [1, 1, 1, 1, 2]), K.dtype(feats))\n",
    "\n",
    "    # Static generation of conv_index:\n",
    "    # conv_index = np.array([_ for _ in np.ndindex(conv_width, conv_height)])\n",
    "    # conv_index = conv_index[:, [1, 0]]  # swap columns for YOLO ordering.\n",
    "    # conv_index = K.variable(\n",
    "    #     conv_index.reshape(1, conv_height, conv_width, 1, 2))\n",
    "    # feats = Reshape(\n",
    "    #     (conv_dims[0], conv_dims[1], num_anchors, num_classes + 5))(feats)\n",
    "\n",
    "    box_xy = K.sigmoid(feats[..., :2])\n",
    "    box_wh = K.exp(feats[..., 2:4])\n",
    "    box_confidence = K.sigmoid(feats[..., 4:5])\n",
    "    box_class_probs = K.softmax(feats[..., 5:])\n",
    "\n",
    "    # Adjust preditions to each spatial grid point and anchor size.\n",
    "    # Note: YOLO iterates over height index before width index.\n",
    "    box_xy = (box_xy + conv_index) / conv_dims\n",
    "    box_wh = box_wh * anchors_tensor / conv_dims\n",
    "\n",
    "    return box_xy, box_wh, box_confidence, box_class_probs\n",
    "\n",
    "\n",
    "def yolo_boxes_to_corners(box_xy, box_wh):\n",
    "    \"\"\"Convert YOLO box predictions to bounding box corners.\"\"\"\n",
    "    box_mins = box_xy - (box_wh / 2.)\n",
    "    box_maxes = box_xy + (box_wh / 2.)\n",
    "\n",
    "    return K.concatenate([\n",
    "        box_mins[..., 1:2],  # y_min\n",
    "        box_mins[..., 0:1],  # x_min\n",
    "        box_maxes[..., 1:2],  # y_max\n",
    "        box_maxes[..., 0:1]  # x_max\n",
    "    ])\n",
    "\n",
    "\n",
    "def yolo_loss(args,\n",
    "              anchors,\n",
    "              num_classes,\n",
    "              rescore_confidence=False,\n",
    "              print_loss=False):\n",
    "    \"\"\"YOLO localization loss function.\n",
    "    Parameters\n",
    "    ----------\n",
    "    yolo_output : tensor\n",
    "        Final convolutional layer features.\n",
    "    true_boxes : tensor\n",
    "        Ground truth boxes tensor with shape [batch, num_true_boxes, 5]\n",
    "        containing box x_center, y_center, width, height, and class.\n",
    "    detectors_mask : array\n",
    "        0/1 mask for detector positions where there is a matching ground truth.\n",
    "    matching_true_boxes : array\n",
    "        Corresponding ground truth boxes for positive detector positions.\n",
    "        Already adjusted for conv height and width.\n",
    "    anchors : tensor\n",
    "        Anchor boxes for model.\n",
    "    num_classes : int\n",
    "        Number of object classes.\n",
    "    rescore_confidence : bool, default=False\n",
    "        If true then set confidence target to IOU of best predicted box with\n",
    "        the closest matching ground truth box.\n",
    "    print_loss : bool, default=False\n",
    "        If True then use a tf.Print() to print the loss components.\n",
    "    Returns\n",
    "    -------\n",
    "    mean_loss : float\n",
    "        mean localization loss across minibatch\n",
    "    \"\"\"\n",
    "    (yolo_output, true_boxes, detectors_mask, matching_true_boxes) = args\n",
    "    num_anchors = len(anchors)\n",
    "    object_scale = 5\n",
    "    no_object_scale = 1\n",
    "    class_scale = 1\n",
    "    coordinates_scale = 1\n",
    "    pred_xy, pred_wh, pred_confidence, pred_class_prob = yolo_head(\n",
    "        yolo_output, anchors, num_classes)\n",
    "\n",
    "    # Unadjusted box predictions for loss.\n",
    "    # TODO: Remove extra computation shared with yolo_head.\n",
    "    yolo_output_shape = K.shape(yolo_output)\n",
    "    feats = K.reshape(yolo_output, [\n",
    "        -1, yolo_output_shape[1], yolo_output_shape[2], num_anchors,\n",
    "        num_classes + 5\n",
    "    ])\n",
    "    pred_boxes = K.concatenate(\n",
    "        (K.sigmoid(feats[..., 0:2]), feats[..., 2:4]), axis=-1)\n",
    "\n",
    "    # TODO: Adjust predictions by image width/height for non-square images?\n",
    "    # IOUs may be off due to different aspect ratio.\n",
    "\n",
    "    # Expand pred x,y,w,h to allow comparison with ground truth.\n",
    "    # batch, conv_height, conv_width, num_anchors, num_true_boxes, box_params\n",
    "    pred_xy = K.expand_dims(pred_xy, 4)\n",
    "    pred_wh = K.expand_dims(pred_wh, 4)\n",
    "\n",
    "    pred_wh_half = pred_wh / 2.\n",
    "    pred_mins = pred_xy - pred_wh_half\n",
    "    pred_maxes = pred_xy + pred_wh_half\n",
    "\n",
    "    true_boxes_shape = K.shape(true_boxes)\n",
    "\n",
    "    # batch, conv_height, conv_width, num_anchors, num_true_boxes, box_params\n",
    "    true_boxes = K.reshape(true_boxes, [\n",
    "        true_boxes_shape[0], 1, 1, 1, true_boxes_shape[1], true_boxes_shape[2]\n",
    "    ])\n",
    "    true_xy = true_boxes[..., 0:2]\n",
    "    true_wh = true_boxes[..., 2:4]\n",
    "\n",
    "    # Find IOU of each predicted box with each ground truth box.\n",
    "    true_wh_half = true_wh / 2.\n",
    "    true_mins = true_xy - true_wh_half\n",
    "    true_maxes = true_xy + true_wh_half\n",
    "\n",
    "    intersect_mins = K.maximum(pred_mins, true_mins)\n",
    "    intersect_maxes = K.minimum(pred_maxes, true_maxes)\n",
    "    intersect_wh = K.maximum(intersect_maxes - intersect_mins, 0.)\n",
    "    intersect_areas = intersect_wh[..., 0] * intersect_wh[..., 1]\n",
    "\n",
    "    pred_areas = pred_wh[..., 0] * pred_wh[..., 1]\n",
    "    true_areas = true_wh[..., 0] * true_wh[..., 1]\n",
    "\n",
    "    union_areas = pred_areas + true_areas - intersect_areas\n",
    "    iou_scores = intersect_areas / union_areas\n",
    "\n",
    "    # Best IOUs for each location.\n",
    "    best_ious = K.max(iou_scores, axis=4)  # Best IOU scores.\n",
    "    best_ious = K.expand_dims(best_ious)\n",
    "\n",
    "    # A detector has found an object if IOU > thresh for some true box.\n",
    "    object_detections = K.cast(best_ious > 0.6, K.dtype(best_ious))\n",
    "\n",
    "    # TODO: Darknet region training includes extra coordinate loss for early\n",
    "    # training steps to encourage predictions to match anchor priors.\n",
    "\n",
    "    # Determine confidence weights from object and no_object weights.\n",
    "    # NOTE: YOLO does not use binary cross-entropy here.\n",
    "    no_object_weights = (no_object_scale * (1 - object_detections) *\n",
    "                         (1 - detectors_mask))\n",
    "    no_objects_loss = no_object_weights * K.square(-pred_confidence)\n",
    "\n",
    "    if rescore_confidence:\n",
    "        objects_loss = (object_scale * detectors_mask *\n",
    "                        K.square(best_ious - pred_confidence))\n",
    "    else:\n",
    "        objects_loss = (object_scale * detectors_mask *\n",
    "                        K.square(1 - pred_confidence))\n",
    "    confidence_loss = objects_loss + no_objects_loss\n",
    "\n",
    "    # Classification loss for matching detections.\n",
    "    # NOTE: YOLO does not use categorical cross-entropy loss here.\n",
    "    matching_classes = K.cast(matching_true_boxes[..., 4], 'int32')\n",
    "    matching_classes = K.one_hot(matching_classes, num_classes)\n",
    "    classification_loss = (class_scale * detectors_mask *\n",
    "                           K.square(matching_classes - pred_class_prob))\n",
    "\n",
    "    # Coordinate loss for matching detection boxes.\n",
    "    matching_boxes = matching_true_boxes[..., 0:4]\n",
    "    coordinates_loss = (coordinates_scale * detectors_mask *\n",
    "                        K.square(matching_boxes - pred_boxes))\n",
    "\n",
    "    confidence_loss_sum = K.sum(confidence_loss)\n",
    "    classification_loss_sum = K.sum(classification_loss)\n",
    "    coordinates_loss_sum = K.sum(coordinates_loss)\n",
    "    total_loss = 0.5 * (\n",
    "        confidence_loss_sum + classification_loss_sum + coordinates_loss_sum)\n",
    "    if print_loss:\n",
    "        total_loss = tf.Print(\n",
    "            total_loss, [\n",
    "                total_loss, confidence_loss_sum, classification_loss_sum,\n",
    "                coordinates_loss_sum\n",
    "            ],\n",
    "            message='yolo_loss, conf_loss, class_loss, box_coord_loss:')\n",
    "\n",
    "    return total_loss\n",
    "\n",
    "\n",
    "def yolo(inputs, anchors, num_classes):\n",
    "    \"\"\"Generate a complete YOLO_v2 localization model.\"\"\"\n",
    "    num_anchors = len(anchors)\n",
    "    body = yolo_body(inputs, num_anchors, num_classes)\n",
    "    outputs = yolo_head(body.output, anchors, num_classes)\n",
    "    return outputs\n",
    "\n",
    "\n",
    "def yolo_filter_boxes(boxes, box_confidence, box_class_probs, threshold=.6):\n",
    "    \"\"\"Filter YOLO boxes based on object and class confidence.\"\"\"\n",
    "    box_scores = box_confidence * box_class_probs\n",
    "    box_classes = K.argmax(box_scores, axis=-1)\n",
    "    box_class_scores = K.max(box_scores, axis=-1)\n",
    "    prediction_mask = box_class_scores >= threshold\n",
    "\n",
    "    # TODO: Expose tf.boolean_mask to Keras backend?\n",
    "    boxes = tf.boolean_mask(boxes, prediction_mask)\n",
    "    scores = tf.boolean_mask(box_class_scores, prediction_mask)\n",
    "    classes = tf.boolean_mask(box_classes, prediction_mask)\n",
    "    return boxes, scores, classes\n",
    "\n",
    "\n",
    "def yolo_eval(yolo_outputs,\n",
    "              image_shape,\n",
    "              max_boxes=10,\n",
    "              score_threshold=.6,\n",
    "              iou_threshold=.5):\n",
    "    \"\"\"Evaluate YOLO model on given input batch and return filtered boxes.\"\"\"\n",
    "    box_xy, box_wh, box_confidence, box_class_probs = yolo_outputs\n",
    "    boxes = yolo_boxes_to_corners(box_xy, box_wh)\n",
    "    boxes, scores, classes = yolo_filter_boxes(\n",
    "        boxes, box_confidence, box_class_probs, threshold=score_threshold)\n",
    "\n",
    "    # Scale boxes back to original image shape.\n",
    "    height = image_shape[0]\n",
    "    width = image_shape[1]\n",
    "    image_dims = K.stack([height, width, height, width])\n",
    "    image_dims = K.reshape(image_dims, [1, 4])\n",
    "    boxes = boxes * image_dims\n",
    "\n",
    "    # TODO: Something must be done about this ugly hack!\n",
    "    max_boxes_tensor = K.variable(max_boxes, dtype='int32')\n",
    "    K.get_session().run(tf.variables_initializer([max_boxes_tensor]))\n",
    "    nms_index = tf.image.non_max_suppression(\n",
    "        boxes, scores, max_boxes_tensor, iou_threshold=iou_threshold)\n",
    "    boxes = K.gather(boxes, nms_index)\n",
    "    scores = K.gather(scores, nms_index)\n",
    "    classes = K.gather(classes, nms_index)\n",
    "    return boxes, scores, classes\n",
    "\n",
    "\n",
    "def preprocess_true_boxes(true_boxes, anchors, image_size):\n",
    "    \"\"\"Find detector in YOLO where ground truth box should appear.\n",
    "    Parameters\n",
    "    ----------\n",
    "    true_boxes : array\n",
    "        List of ground truth boxes in form of relative x, y, w, h, class.\n",
    "        Relative coordinates are in the range [0, 1] indicating a percentage\n",
    "        of the original image dimensions.\n",
    "    anchors : array\n",
    "        List of anchors in form of w, h.\n",
    "        Anchors are assumed to be in the range [0, conv_size] where conv_size\n",
    "        is the spatial dimension of the final convolutional features.\n",
    "    image_size : array-like\n",
    "        List of image dimensions in form of h, w in pixels.\n",
    "    Returns\n",
    "    -------\n",
    "    detectors_mask : array\n",
    "        0/1 mask for detectors in [conv_height, conv_width, num_anchors, 1]\n",
    "        that should be compared with a matching ground truth box.\n",
    "    matching_true_boxes: array\n",
    "        Same shape as detectors_mask with the corresponding ground truth box\n",
    "        adjusted for comparison with predicted parameters at training time.\n",
    "    \"\"\"\n",
    "    height, width = image_size\n",
    "    num_anchors = len(anchors)\n",
    "    # Downsampling factor of 5x 2-stride max_pools == 32.\n",
    "    # TODO: Remove hardcoding of downscaling calculations.\n",
    "    assert height % 32 == 0, 'Image sizes in YOLO_v2 must be multiples of 32.'\n",
    "    assert width % 32 == 0, 'Image sizes in YOLO_v2 must be multiples of 32.'\n",
    "    conv_height = height // 32\n",
    "    conv_width = width // 32\n",
    "    num_box_params = true_boxes.shape[1]\n",
    "    detectors_mask = np.zeros(\n",
    "        (conv_height, conv_width, num_anchors, 1), dtype=np.float32)\n",
    "    matching_true_boxes = np.zeros(\n",
    "        (conv_height, conv_width, num_anchors, num_box_params),\n",
    "        dtype=np.float32)\n",
    "\n",
    "    for box in true_boxes:\n",
    "        # scale box to convolutional feature spatial dimensions\n",
    "        box_class = box[4:5]\n",
    "        box = box[0:4] * np.array(\n",
    "            [conv_width, conv_height, conv_width, conv_height])\n",
    "        i = np.floor(box[1]).astype('int')\n",
    "        j = np.floor(box[0]).astype('int')\n",
    "        best_iou = 0\n",
    "        best_anchor = 0\n",
    "        for k, anchor in enumerate(anchors):\n",
    "            # Find IOU between box shifted to origin and anchor box.\n",
    "            box_maxes = box[2:4] / 2.\n",
    "            box_mins = -box_maxes\n",
    "            anchor_maxes = (anchor / 2.)\n",
    "            anchor_mins = -anchor_maxes\n",
    "\n",
    "            intersect_mins = np.maximum(box_mins, anchor_mins)\n",
    "            intersect_maxes = np.minimum(box_maxes, anchor_maxes)\n",
    "            intersect_wh = np.maximum(intersect_maxes - intersect_mins, 0.)\n",
    "            intersect_area = intersect_wh[0] * intersect_wh[1]\n",
    "            box_area = box[2] * box[3]\n",
    "            anchor_area = anchor[0] * anchor[1]\n",
    "            iou = intersect_area / (box_area + anchor_area - intersect_area)\n",
    "            if iou > best_iou:\n",
    "                best_iou = iou\n",
    "                best_anchor = k\n",
    "\n",
    "        if best_iou > 0:\n",
    "            detectors_mask[i, j, best_anchor] = 1\n",
    "            adjusted_box = np.array(\n",
    "                [\n",
    "                    box[0] - j, box[1] - i,\n",
    "                    np.log(box[2] / anchors[best_anchor][0]),\n",
    "                    np.log(box[3] / anchors[best_anchor][1]), box_class\n",
    "                ],\n",
    "                dtype=np.float32)\n",
    "            matching_true_boxes[i, j, best_anchor] = adjusted_box\n",
    "    return detectors_mask, matching_true_boxes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_block(x, filters, block_number, size=3, stride=1, pad='same', alpha=0.1, relu_activation= True):\n",
    "    x = Conv2D(filters, (size,size), strides=(stride,stride), padding=pad, name='conv_' + str(block_number))(x)\n",
    "    x = BatchNormalization(name='norm_' + str(block_number))(x)\n",
    "    if relu_activation== True :\n",
    "        x = LeakyReLU(alpha=alpha)(x)\n",
    "    return x\n",
    "\n",
    "def maxpool_block(x, pool_size=2, stride=2):\n",
    "    return MaxPooling2D(pool_size=pool_size, strides=stride)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model(model_input):\n",
    "    conv1 = conv_block(model_input, 32, 1)\n",
    "    pool1 = maxpool_block(conv1)\n",
    "    conv2 = conv_block(pool1, 64, 2)\n",
    "    pool2 = maxpool_block(conv2)\n",
    "    \n",
    "    conv3 = conv_block(pool2, 128, 3)\n",
    "    conv4 = conv_block(conv3, 64, 4, size=1)\n",
    "    conv5 = conv_block(conv4, 128, 5)\n",
    "    pool3 = maxpool_block(conv5)\n",
    "    \n",
    "    conv6 = conv_block(pool3, 256, 6)\n",
    "    conv7 = conv_block(conv6, 128, 7,size=1)\n",
    "    conv8 = conv_block(conv7, 256, 8)\n",
    "    pool4 = maxpool_block(conv8)\n",
    "    \n",
    "    conv9 = conv_block(pool4, 512, 9)\n",
    "    conv10 = conv_block(conv9, 256, 10,size=1)\n",
    "    conv11 = conv_block(conv10, 512, 11)\n",
    "    conv12 = conv_block(conv11, 256, 12,size=1)\n",
    "    conv13 = conv_block(conv12, 512, 13)\n",
    "    pool5 = maxpool_block(conv13)\n",
    "    \n",
    "    conv14 = conv_block(pool5, 1024, 14)\n",
    "    conv15 = conv_block(conv14, 512, 15, size=1)\n",
    "    conv16 = conv_block(conv15, 1024, 16)\n",
    "    conv17 = conv_block(conv16, 512, 17, size=1)\n",
    "    conv18 = conv_block(conv17, 1024, 18)\n",
    "    \n",
    "    conv19 = conv_block(conv15, 1024, 19)\n",
    "    conv20 = conv_block(conv16, 1024, 20, size=1)\n",
    "    conv21 = conv_block(conv13, 64, size=1)\n",
    "    \n",
    "    conv21_reshaped = Lambda(\n",
    "        space_to_depth_x2,\n",
    "        output_shape=space_to_depth_x2_output_shape,\n",
    "        name='space_to_depth')(conv21)\n",
    "    merge = concatenate([conv21_reshaped, conv20])\n",
    "    x = conv_block(merge, 1024, 22)(merge)\n",
    "    x = conv_block(x, num_anchors * (num_classes + 5), size=1)(x)\n",
    "    return Model(model_input, x)\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
