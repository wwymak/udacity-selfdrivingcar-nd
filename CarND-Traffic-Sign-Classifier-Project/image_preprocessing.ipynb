{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from sklearn.utils import class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, Conv2D, MaxPooling2D\n",
    "from keras import utils\n",
    "from keras.callbacks import Callback, LambdaCallback, EarlyStopping, ModelCheckpoint\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.optimizers import Adadelta, Adam\n",
    "from keras import backend as K\n",
    "from keras.preprocessing import image\n",
    "from keras.layers.normalization import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "training_file = './data/train.p'\n",
    "validation_file= './data/valid.p'\n",
    "testing_file = './data/test.p'\n",
    "\n",
    "with open(training_file, mode='rb') as f:\n",
    "    train = pickle.load(f)\n",
    "with open(validation_file, mode='rb') as f:\n",
    "    valid = pickle.load(f)\n",
    "with open(testing_file, mode='rb') as f:\n",
    "    test = pickle.load(f)\n",
    "    \n",
    "X_train, y_train = train['features'], train['labels']\n",
    "X_valid, y_valid = valid['features'], valid['labels']\n",
    "X_test, y_test = test['features'], test['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_classes = 43\n",
    "y_train_cat = utils.to_categorical(y_train, n_classes)\n",
    "y_valid_cat = utils.to_categorical(y_valid, n_classes)\n",
    "y_test_cat = utils.to_categorical(y_test, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean_train = np.mean(X_train)\n",
    "std_train = np.std(X_train)\n",
    "min_train = np.min(X_train)\n",
    "max_train = np.max(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67.850888426332318"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def histogramEqualisation(img):\n",
    "    original_type = img.dtype\n",
    "    if img.dtype != 'uint8':\n",
    "        img = img.astype('uint8')\n",
    "    img_yuv = cv2.cvtColor(img, cv2.COLOR_RGB2YUV)\n",
    "    img_yuv[:,:,0] = cv2.equalizeHist(img_yuv[:,:,0])\n",
    "    equalised = cv2.cvtColor(img_yuv, cv2.COLOR_YUV2RGB)\n",
    "    return equalised.astype(original_type)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def hist(X):\n",
    "    out = []\n",
    "    for i in range(len(X)):\n",
    "        out.append(histogramEqualisation(X[i]))\n",
    "    return np.array(out)\n",
    "X_train_histogram =  hist(X_train)\n",
    "X_valid_histogram = hist(X_valid)\n",
    "X_test_histogram =  hist(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mean_hist_train = np.mean(X_train_histogram)\n",
    "std_hist_train = np.std(X_train_histogram)\n",
    "min_hist_train = np.min(X_train_histogram)\n",
    "max_hist_train = np.max(X_train_histogram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mean_hist_values = {\n",
    "    'mean_hist_train': mean_hist_train,\n",
    "    'std_hist_train': std_hist_train,\n",
    "    'min_hist_train': min_hist_train,\n",
    "    'max_hist_train': max_hist_train\n",
    "}\n",
    "np.save(\"data/mean_hist_values.npy\", mean_hist_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalise1(x, is_hist = True):\n",
    "    if is_hist == True:        \n",
    "        return (x - min_hist_train) / (max_hist_train - min_hist_train)\n",
    "    else:\n",
    "        return (x - min_train) / (max_train - min_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalise2(x, is_hist = True):\n",
    "    if is_hist == True:        \n",
    "        return (x - mean_hist_train) /std_hist_train\n",
    "    else:\n",
    "        return (x - mean_train) /std_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_norm1 = normalise1(X_train, False)\n",
    "X_valid_norm1 = normalise1(X_valid, False)\n",
    "X_test_norm1 = normalise1(X_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_hist_norm1 = normalise1(X_train_histogram)\n",
    "X_valid_hist_norm1 = normalise1(X_valid_histogram)\n",
    "X_test_hist_norm1 = normalise1(X_test_histogram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('data/X_train_hist_norm1.npy', X_train_hist_norm1)\n",
    "np.save('data/X_valid_hist_norm1.npy', X_valid_hist_norm1)\n",
    "np.save('data/X_test_hist_norm1.npy', X_test_hist_norm1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 4.4959948320413439, 1: 0.40872680291284941, 2: 0.40262640286937407, 3: 0.64228497600590628, 4: 0.45721981342793327, 5: 0.49047216349541933, 6: 2.2479974160206719, 7: 0.62734811609879215, 8: 0.64228497600590628, 9: 0.61309020436927408, 10: 0.44959948320413434, 11: 0.69169151262174522, 12: 0.42818998400393748, 13: 0.42149951550387599, 14: 1.1728682170542635, 15: 1.4986649440137811, 16: 2.2479974160206719, 17: 0.81745360582569881, 18: 0.74933247200689057, 19: 4.4959948320413439, 20: 2.6975968992248061, 21: 2.9973298880275623, 22: 2.4523608174770963, 23: 1.7983979328165374, 24: 3.3719961240310079, 25: 0.59946597760551246, 26: 1.4986649440137811, 27: 3.8537098560354375, 28: 1.685998062015504, 29: 3.3719961240310079, 30: 2.0750745378652353, 31: 1.1728682170542635, 32: 3.8537098560354375, 33: 1.3510501999456459, 34: 2.2479974160206719, 35: 0.74933247200689057, 36: 2.4523608174770963, 37: 4.4959948320413439, 38: 0.43509627406851714, 39: 2.9973298880275623, 40: 2.6975968992248061, 41: 3.8537098560354375, 42: 3.8537098560354375}\n"
     ]
    }
   ],
   "source": [
    "class_weight_arr = class_weight.compute_class_weight('balanced', np.unique(y_train), y_train)\n",
    "class_weight_dict = {}\n",
    "for i, val in enumerate(class_weight_arr) :\n",
    "    class_weight_dict[i] = val\n",
    "    \n",
    "print(class_weight_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logger(epoch, logs):\n",
    "    if epoch %2== 0: \n",
    "        print(epoch, logs['loss'], logs['acc'], logs['val_acc'])\n",
    "logging_callback = LambdaCallback(\n",
    "    on_epoch_end=logger)\n",
    "\n",
    "stopping_callback = EarlyStopping(monitor='val_acc', min_delta= 0.001, patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vggLike(ksize=(3,3), dropout=0.25): #taking my inspiration from vgg, a deeper network\n",
    "    input_shape = (32,32,3)\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=ksize, activation='relu', padding='same', name='set1_conv1',input_shape=input_shape))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(32, kernel_size=ksize, activation='relu', padding='same', name='set1_conv2'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2),strides=(2, 2), name='set1_pool'))\n",
    "    \n",
    "    model.add(Conv2D(64, kernel_size=ksize, activation='relu', padding='same', name='set2_conv1'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(64, kernel_size=ksize, activation='relu', padding='same', name='set2_conv2'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(64, kernel_size=ksize, activation='relu', padding='same', name='set2_conv3'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2),name='set2_pool'))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024, activation='relu', name='fc1'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(512, activation='relu' , name='fc2'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(n_classes, activation='softmax', name='final'))\n",
    "    model.compile(loss=categorical_crossentropy,\n",
    "              optimizer=Adam(),\n",
    "              metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.597767194567 0.822006379494 0.864172335601\n",
      "2 0.0731623331159 0.973476249347 0.847392290439\n",
      "4 0.0520341100796 0.981896031495 0.962811791762\n",
      "6 0.0535931652948 0.983936320009 0.861678004751\n",
      "8 0.0176450696367 0.993131986551 0.921315192933\n",
      "10 0.0153261176096 0.993936607374 0.963718820916\n",
      "12 0.0322363908751 0.989769820999 0.974603174684\n",
      "14 0.0238003399633 0.992700939682 0.972562358277\n",
      "16 0.00594484336654 0.99775855628 0.976417233749\n",
      "18 0.00721026885841 0.997011408401 0.984126984127\n",
      "20 0.0189481068547 0.994741228196 0.977551020597\n",
      "22 0.0104353533608 0.996609097963 0.97596371901\n",
      "24 0.0101688605366 0.99678151671 0.985034013605\n",
      "26 0.00821094157116 0.997126354206 0.974149659864\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m----------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-34e08b74f620>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m vgglikeHistory = vgglike.fit(X_train_hist_norm1, y_train_cat, batch_size=batch_size,\n\u001b[1;32m      8\u001b[0m               \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid_hist_norm1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid_cat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                 class_weight=class_weight_dict, callbacks=[logging_callback])\n\u001b[0m",
      "\u001b[0;32m/root/anaconda3/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    958\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 960\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    961\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/root/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1648\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1649\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1650\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1652\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/root/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1211\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1213\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1214\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2350\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2351\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2352\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2353\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "del vgglike\n",
    "K.clear_session()\n",
    "image_shape = (X_train.shape[1], X_train.shape[2], X_train.shape[3] )\n",
    "batch_size = 32\n",
    "epochs = 80\n",
    "vgglike = vggLike(ksize=(3,3))\n",
    "vgglikeHistory = vgglike.fit(X_train_hist_norm1, y_train_cat, batch_size=batch_size,\n",
    "              epochs=epochs, verbose=0,shuffle=True, validation_data=(X_valid_hist_norm1, y_valid_cat), \n",
    "                class_weight=class_weight_dict, callbacks=[logging_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vgglike.save('models/vgglike_hist_normed1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.20368701582887203, 0.96476642915585265]\n"
     ]
    }
   ],
   "source": [
    "score = vgglike.evaluate(X_test_hist_norm1, y_test_cat, verbose=0)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# datagenerator = image.ImageDataGenerator(\n",
    "#     rotation_range=30.,\n",
    "#     width_shift_range=0.2,\n",
    "#     height_shift_range=0.2,\n",
    "#     shear_range=0.5,\n",
    "#     zoom_range=0.3,\n",
    "#     fill_mode='nearest',\n",
    "#     horizontal_flip=False,\n",
    "#     vertical_flip=False\n",
    "# )\n",
    "# valid_generator = image.ImageDataGenerator(\n",
    "# )\n",
    "\n",
    "\n",
    "datagen = image.ImageDataGenerator(\n",
    "    featurewise_center=False,\n",
    "    featurewise_std_normalization=False,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=0.2,\n",
    "    shear_range=0.1,\n",
    "    rotation_range=10.)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_generator = datagenerator.flow(X_train_hist_norm1, y_train_cat)\n",
    "validation_generator = valid_generator.flow(X_valid_hist_norm1, y_valid_cat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.06402726292 0.689416362551 0.883446712397\n",
      "2 0.183936847253 0.941061524784 0.965079365079\n",
      "4 0.12060290602 0.962182821345 0.978458050076\n",
      "6 0.0866339539031 0.972901520186 0.989115646259\n",
      "8 0.0686426073648 0.978677548205 0.960317460507\n",
      "10 0.0586404841519 0.981436248168 0.977097505669\n",
      "12 0.0547620543993 0.983735164804 0.98752834486\n",
      "14 0.044346064035 0.986752492888 0.987528344671\n",
      "16 0.03654052597 0.988275525159 0.991383219955\n",
      "18 0.0392438928912 0.987585850197 0.992743764172\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f96ba128c50>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# del vgglike\n",
    "K.clear_session()\n",
    "image_shape = (X_train.shape[1], X_train.shape[2], X_train.shape[3] )\n",
    "batch_size = 32\n",
    "epochs = 20\n",
    "vgglike = vggLike(ksize=(3,3))\n",
    "\n",
    "vgglike.fit_generator(datagen.flow(X_train_hist_norm1, y_train_cat, batch_size=batch_size),\n",
    "                    steps_per_epoch=X_train_hist_norm1.shape[0],\n",
    "                    epochs=epochs,\n",
    "                      verbose=0,\n",
    "                    validation_data=(X_valid_hist_norm1, y_valid_cat),\n",
    "                    callbacks=[logging_callback,\n",
    "                               ModelCheckpoint('models/vgglike_image_gen2.h5', save_best_only=True)\n",
    "                              ])\n",
    "\n",
    "# vgglike.fit_generator(\n",
    "#     train_generator,\n",
    "#     steps_per_epoch=len(X_train_hist_norm1) // batch_size,\n",
    "#     epochs=epochs, \n",
    "#     verbose=0,shuffle=True, \n",
    "#     class_weight=class_weight_dict,\n",
    "#     validation_data=validation_generator,\n",
    "#     validation_steps=800 // batch_size,\n",
    "#     callbacks=[logging_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.11079416088137381, 0.97205067301966896]\n"
     ]
    }
   ],
   "source": [
    "print(vgglike.evaluate(X_test_hist_norm1, y_test_cat, verbose=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.0303572981815 0.990085922037 0.985487528345\n",
      "2 0.0256590855101 0.991321589701 0.991836734694\n",
      "4 0.0244580753975 0.992499784477 0.988888888889\n",
      "6 0.0298349802263 0.990689387653 0.990022675737\n",
      "8 0.0289730039021 0.991235380327 0.993424036281\n",
      "10 0.0234103601955 0.992758412598 0.992290249622\n",
      "12 0.0242696679092 0.992471048046 0.989115646259\n",
      "14 0.0211164894733 0.993907870916 0.993650793651\n",
      "16 0.0184709816037 0.993907870916 0.993197279101\n",
      "18 0.0177420368183 0.994568809449 0.995238095238\n",
      "20 0.0198395129052 0.994281444869 0.994557823129\n",
      "22 0.0176456950333 0.994482600075 0.995464852608\n",
      "24 0.0174676853557 0.994597545936 0.996145124717\n",
      "26 0.0149277747416 0.99566079485 0.984580499055\n",
      "28 0.0134316799115 0.995976895888 0.994557823129\n",
      "30 0.0152622894274 0.995430903187 0.994784580499\n",
      "32 0.0140344789819 0.995373430271 0.992290249433\n",
      "34 0.012915414671 0.99609184172 0.994557823129\n",
      "36 0.0132369597519 0.995833213598 0.992063492063\n",
      "38 0.0148237850656 0.995143538635 0.99387755102\n",
      "40 0.0130026365038 0.996235524009 0.991609977324\n",
      "42 0.0123481152807 0.996292996925 0.993424036281\n",
      "44 0.0130790600383 0.996178051093 0.992517006803\n",
      "46 0.0137629551691 0.996379206299 0.992743764172\n",
      "48 0.0126505132088 0.996551625047 0.99433106576\n",
      "50 0.0101965462385 0.99678151671 0.990476190476\n",
      "52 0.0123734470888 0.996063105262 0.99387755102\n",
      "54 0.0097415733 0.996925199 0.995238095427\n",
      "56 0.0104500677692 0.996982671916 0.992743764172\n",
      "58 0.0103128147023 0.997040144832 0.99410430839\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f96b9f44eb8>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 60\n",
    "vgglike.fit_generator(datagen.flow(X_train_hist_norm1, y_train_cat, batch_size=batch_size),\n",
    "                    steps_per_epoch=X_train_hist_norm1.shape[0],\n",
    "                    epochs=epochs,\n",
    "                      verbose=0,\n",
    "                    validation_data=(X_valid_hist_norm1, y_valid_cat),\n",
    "                    callbacks=[logging_callback,\n",
    "                               ModelCheckpoint('models/vgglike_image_gen3.h5', save_best_only=True)\n",
    "                              ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.078267840725359139, 0.98456057011845177]\n"
     ]
    }
   ],
   "source": [
    "print(vgglike.evaluate(X_test_hist_norm1, y_test_cat, verbose=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test images from the wild\n",
    "from scipy.misc import imread, imresize\n",
    "\n",
    "img1 = imread('data/traffic_sign1.jpg')\n",
    "img2 = imread('data/traffic_sign14.jpg')\n",
    "img3 = imread('data/traffic_sign0.jpg')\n",
    "img4 = imread('data/traffic_sign17.jpg')\n",
    "img5 = imread('data/traffic_sign35.jpg')\n",
    "img6 = imread('data/traffic_sign2.jpg')\n",
    "img7 = imread('data/traffic_sign22.jpg')\n",
    "img8 = imread('data/traffic_sign4.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "imglist = [img1, img2, img3, img4, img5, img6, img7, img8]\n",
    "test_imgs = []\n",
    "for i, img in enumerate(imglist):\n",
    "    test_imgs.append(imresize(img,( 32,32)))\n",
    "test_imgs_arr = np.array(test_imgs)\n",
    "test_imgs_classes = np.array([1,14,0, 17,35, 2, 22,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test2_hist = normalise1(test_imgs_arr)\n",
    "n_classes = 43\n",
    "y_test2_cat = utils.to_categorical(test_imgs_classes, n_classes)\n",
    "\n",
    "np.save('data/X_test2_hist_normed.npy',X_test2_hist )\n",
    "np.save('data/y_test2_cat.npy', y_test2_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
